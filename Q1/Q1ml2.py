# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆ æ³•åŒ»DNAåˆ†æ - é—®é¢˜1ï¼šè´¡çŒ®è€…äººæ•°è¯†åˆ«
ç‰ˆæœ¬: 4.0 (å¢å¼ºç‰ˆ)
æ–°å¢åŠŸèƒ½:
1. è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š - æ¯ä¸ªæ¨¡å‹å¯¹ä¸åŒäººæ•°çš„ç²¾ç¡®è¡¨ç°
2. å¤šç§èšç±»ç®—æ³•æµ‹è¯•
3. æ— ç›‘ç£å­¦ä¹ ç»“æœä¸æœ‰ç›‘ç£å­¦ä¹ å¯¹æ¯”
4. æ›´å…¨é¢çš„æ€§èƒ½è¯„ä¼°
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
import json
import re
from scipy import stats
from collections import Counter

# æœºå™¨å­¦ä¹ ç›¸å…³
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB

# èšç±»ç®—æ³•
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, SpectralClustering
from sklearn.mixture import GaussianMixture
from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score
from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score

# å¯é€‰çš„é«˜çº§ç®—æ³•
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    print("XGBoostä¸å¯ç”¨ï¼Œå°†è·³è¿‡")
    XGBOOST_AVAILABLE = False

# é…ç½®
warnings.filterwarnings('ignore')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10
plt.rcParams['font.sans-serif'] = ["Arial Unicode MS", "SimHei"]
plt.rcParams['axes.unicode_minus'] = False

# æ–‡ä»¶è·¯å¾„
DATA_DIR = './'
file_path = os.path.join(DATA_DIR, 'é™„ä»¶1ï¼šä¸åŒäººæ•°çš„STRå›¾è°±æ•°æ®.csv')
PLOTS_DIR = os.path.join(DATA_DIR, 'q1_enhanced_plots_v4')
if not os.path.exists(PLOTS_DIR):
    os.makedirs(PLOTS_DIR)

print("=== å¢å¼ºç‰ˆ NoC è¯†åˆ«ç³»ç»Ÿ v4.0 ===")
print("æ–°å¢: è¯¦ç»†åˆ†ç±»æŠ¥å‘Š + èšç±»åˆ†æ")

# =====================
# 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç† (ä¿æŒä¸å˜)
# =====================
print("\n1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†...")

def extract_noc_from_filename(filename):
    """ä»æ–‡ä»¶åæå–è´¡çŒ®è€…äººæ•°"""
    match = re.search(r'-(\d+(?:_\d+)*)-[\d;]+-', str(filename))
    if match:
        ids = [id_val for id_val in match.group(1).split('_') if id_val.isdigit()]
        return len(ids) if len(ids) > 0 else np.nan
    return np.nan

# åŠ è½½æ•°æ®
try:
    df = pd.read_csv(file_path, encoding='utf-8')
    print(f"æˆåŠŸåŠ è½½æ•°æ®ï¼Œå½¢çŠ¶: {df.shape}")
except Exception as e:
    print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
    exit()

# æå–NoC
df['NoC_True'] = df['Sample File'].apply(extract_noc_from_filename)
df = df.dropna(subset=['NoC_True'])
df['NoC_True'] = df['NoC_True'].astype(int)

print(f"NoCåˆ†å¸ƒ: {df['NoC_True'].value_counts().sort_index().to_dict()}")
print(f"æ ·æœ¬æ•°: {df['Sample File'].nunique()}")

# =====================
# 2. ç®€åŒ–çš„å³°å¤„ç† (ä¿æŒä¸å˜)
# =====================
print("\n2. ç®€åŒ–çš„å³°å¤„ç†...")

def process_peaks_simplified(sample_data, height_threshold=50, saturation_threshold=30000):
    """ç®€åŒ–çš„å³°å¤„ç†å‡½æ•°"""
    processed_data = []
    
    for _, sample_row in sample_data.iterrows():
        sample_file = sample_row['Sample File']
        marker = sample_row['Marker']
        
        peaks = []
        for i in range(1, 101):
            allele = sample_row.get(f'Allele {i}')
            size = sample_row.get(f'Size {i}')
            height = sample_row.get(f'Height {i}')
            
            if pd.notna(allele) and pd.notna(size) and pd.notna(height):
                corrected_height = min(float(height), saturation_threshold)
                
                if corrected_height >= height_threshold:
                    peaks.append({
                        'Sample File': sample_file,
                        'Marker': marker,
                        'Allele': allele,
                        'Size': float(size),
                        'Height': corrected_height,
                        'Original_Height': float(height)
                    })
        
        processed_data.extend(peaks)
    
    return pd.DataFrame(processed_data)

# å¤„ç†æ‰€æœ‰æ ·æœ¬
all_processed_peaks = []
for sample_file, group in df.groupby('Sample File'):
    sample_peaks = process_peaks_simplified(group)
    all_processed_peaks.append(sample_peaks)

df_peaks = pd.concat(all_processed_peaks, ignore_index=True)
print(f"å¤„ç†åçš„å³°æ•°æ®å½¢çŠ¶: {df_peaks.shape}")

# =====================
# 3. å¢å¼ºç‰¹å¾å·¥ç¨‹ (ä¿æŒä¸å˜)
# =====================
print("\n3. å¢å¼ºç‰¹å¾å·¥ç¨‹...")

def extract_comprehensive_features(sample_file, sample_peaks, marker_info=None):
    """åŸºäºV5æ–¹æ¡ˆçš„ç»¼åˆç‰¹å¾æå–"""
    if sample_peaks.empty:
        return {}
    
    features = {'Sample File': sample_file}
    
    # åŸºç¡€ç»Ÿè®¡
    total_peaks = len(sample_peaks)
    all_heights = sample_peaks['Height'].values
    all_sizes = sample_peaks['Size'].values
    
    # A. å›¾è°±å±‚é¢åŸºç¡€è®¡æ•°ä¸ç»Ÿè®¡ç‰¹å¾
    alleles_per_locus = sample_peaks.groupby('Marker')['Allele'].nunique()
    
    features['mac_profile'] = alleles_per_locus.max() if len(alleles_per_locus) > 0 else 0
    features['total_distinct_alleles'] = sample_peaks['Allele'].nunique()
    features['avg_alleles_per_locus'] = alleles_per_locus.mean() if len(alleles_per_locus) > 0 else 0
    features['std_alleles_per_locus'] = alleles_per_locus.std() if len(alleles_per_locus) > 1 else 0
    features['num_effective_loci'] = len(alleles_per_locus)
    
    # MGTNç³»åˆ—
    for n in [2, 3, 4, 5, 6]:
        features[f'loci_gt{n}_alleles'] = (alleles_per_locus >= n).sum()
    
    # ç­‰ä½åŸºå› æ•°åˆ†å¸ƒçš„ç†µ
    if len(alleles_per_locus) > 0:
        counts = alleles_per_locus.value_counts(normalize=True)
        features['allele_count_entropy'] = -np.sum(counts * np.log(counts + 1e-10))
    else:
        features['allele_count_entropy'] = 0
    
    # B. å³°é«˜ç›¸å…³ç‰¹å¾
    if total_peaks > 0:
        features['avg_peak_height'] = np.mean(all_heights)
        features['std_peak_height'] = np.std(all_heights) if total_peaks > 1 else 0
        features['cv_peak_height'] = features['std_peak_height'] / features['avg_peak_height'] if features['avg_peak_height'] > 0 else 0
        features['skewness_peak_height'] = stats.skew(all_heights) if total_peaks > 2 else 0
        features['kurtosis_peak_height'] = stats.kurtosis(all_heights) if total_peaks > 3 else 0
        features['min_peak_height'] = np.min(all_heights)
        features['max_peak_height'] = np.max(all_heights)
        features['peak_height_range'] = features['max_peak_height'] - features['min_peak_height']
    else:
        for key in ['avg_peak_height', 'std_peak_height', 'cv_peak_height', 'skewness_peak_height', 
                   'kurtosis_peak_height', 'min_peak_height', 'max_peak_height', 'peak_height_range']:
            features[key] = 0
    
    # å³°é«˜åˆ†å¸ƒç‰¹å¾
    if total_peaks > 0:
        hist, _ = np.histogram(np.log(all_heights + 1), bins=min(10, total_peaks))
        probs = hist / hist.sum()
        probs = probs[probs > 0]
        features['peak_height_entropy'] = -np.sum(probs * np.log(probs)) if len(probs) > 0 else 0
        
        height_threshold_80 = np.percentile(all_heights, 80)
        features['high_peaks_ratio'] = (all_heights >= height_threshold_80).mean()
    else:
        features['peak_height_entropy'] = 0
        features['high_peaks_ratio'] = 0
    
    # C. å³°é«˜æ¯”(PHR)ç›¸å…³ç‰¹å¾
    phr_values = []
    for marker, marker_group in sample_peaks.groupby('Marker'):
        if len(marker_group) == 2:
            heights = marker_group['Height'].values
            phr = min(heights) / max(heights)
            phr_values.append(phr)
    
    if phr_values:
        features['avg_phr'] = np.mean(phr_values)
        features['std_phr'] = np.std(phr_values) if len(phr_values) > 1 else 0
        features['min_phr'] = np.min(phr_values)
        features['median_phr'] = np.median(phr_values)
        features['num_loci_with_phr'] = len(phr_values)
        features['imbalance_ratio'] = (np.array(phr_values) < 0.6).mean()
    else:
        for key in ['avg_phr', 'std_phr', 'min_phr', 'median_phr', 'num_loci_with_phr', 'imbalance_ratio']:
            features[key] = 0
    
    # D. ä½ç‚¹é—´å¹³è¡¡æ€§
    locus_heights = sample_peaks.groupby('Marker')['Height'].sum()
    if len(locus_heights) > 0:
        total_height = locus_heights.sum()
        locus_probs = locus_heights / total_height
        features['inter_locus_entropy'] = -np.sum(locus_probs * np.log(locus_probs + 1e-10))
        features['locus_height_cv'] = locus_heights.std() / locus_heights.mean() if locus_heights.mean() > 0 else 0
    else:
        features['inter_locus_entropy'] = 0
        features['locus_height_cv'] = 0
    
    # E. ä½ç‚¹å†…ç­‰ä½åŸºå› åˆ†å¸ƒç†µ
    locus_entropies = []
    for marker, marker_group in sample_peaks.groupby('Marker'):
        heights = marker_group['Height'].values
        if len(heights) > 1:
            probs = heights / heights.sum()
            entropy = -np.sum(probs * np.log(probs + 1e-10))
            locus_entropies.append(entropy)
    
    features['avg_locus_allele_entropy'] = np.mean(locus_entropies) if locus_entropies else 0
    
    # F. å¤§å°ç›¸å…³ç‰¹å¾
    if total_peaks > 1:
        features['height_size_correlation'] = np.corrcoef(all_heights, all_sizes)[0, 1] if len(np.unique(all_heights)) > 1 and len(np.unique(all_sizes)) > 1 else 0
        
        if len(np.unique(all_sizes)) > 1:
            slope, _, _, _, _ = stats.linregress(all_sizes, all_heights)
            features['height_size_slope'] = slope
        else:
            features['height_size_slope'] = 0
            
        features['size_range'] = all_sizes.max() - all_sizes.min()
        features['avg_size'] = np.mean(all_sizes)
        features['std_size'] = np.std(all_sizes)
    else:
        features['height_size_correlation'] = 0
        features['height_size_slope'] = 0
        features['size_range'] = 0
        features['avg_size'] = 0
        features['std_size'] = 0
    
    # G. å¤æ‚åº¦æŒ‡æ ‡
    features['total_peaks'] = total_peaks
    features['unique_markers'] = sample_peaks['Marker'].nunique()
    features['peaks_per_marker'] = total_peaks / features['unique_markers'] if features['unique_markers'] > 0 else 0
    
    # H. å¤åˆç‰¹å¾
    features['complexity_score'] = features['mac_profile'] * features['avg_alleles_per_locus']
    features['balance_score'] = features['avg_phr'] * (1 - features['locus_height_cv'])
    features['quality_score'] = features['avg_peak_height'] / (features['std_peak_height'] + 1)
    
    return features

# æå–æ‰€æœ‰æ ·æœ¬çš„ç‰¹å¾
print("æå–ç‰¹å¾ä¸­...")
all_features = []
for sample_file, group in df_peaks.groupby('Sample File'):
    features = extract_comprehensive_features(sample_file, group)
    all_features.append(features)

df_features = pd.DataFrame(all_features)

# åˆå¹¶NoCæ ‡ç­¾
noc_map = df.groupby('Sample File')['NoC_True'].first().to_dict()
df_features['NoC_True'] = df_features['Sample File'].map(noc_map)
df_features = df_features.dropna(subset=['NoC_True'])

print(f"ç‰¹å¾æ•°æ®å½¢çŠ¶: {df_features.shape}")
print(f"ç‰¹å¾åˆ—æ•°: {len([col for col in df_features.columns if col not in ['Sample File', 'NoC_True']])}")

# =====================
# 4. å¤šç§æœºå™¨å­¦ä¹ ç®—æ³•æµ‹è¯• (å¢å¼ºç‰ˆ)
# =====================
print("\n4. å¤šç§æœºå™¨å­¦ä¹ ç®—æ³•æµ‹è¯•...")

# å‡†å¤‡æ•°æ®
feature_cols = [col for col in df_features.columns if col not in ['Sample File', 'NoC_True']]
X = df_features[feature_cols].fillna(0)
y = df_features['NoC_True']

print(f"åŸå§‹NoCæ ‡ç­¾: {sorted(y.unique())}")

# ä¸ºç®—æ³•é‡æ–°ç¼–ç æ ‡ç­¾
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
y_original = y.copy()

print(f"ç¼–ç åæ ‡ç­¾: {sorted(np.unique(y_encoded))} (å¯¹åº”åŸå§‹: {sorted(y.unique())})")

# æ ‡å‡†åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=feature_cols)

# åˆ’åˆ†æ•°æ®é›†
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded
)

# åŒæ—¶ä¿å­˜åŸå§‹æ ‡ç­¾ç”¨äºæ˜¾ç¤º
_, _, y_train_orig, y_test_orig = train_test_split(
    X_scaled, y_original, test_size=0.3, random_state=42, stratify=y_encoded
)

# äº¤å‰éªŒè¯è®¾ç½®
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# å®šä¹‰ç®—æ³•
algorithms = {
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42, class_weight='balanced'),
    'SVM': SVC(probability=True, random_state=42, class_weight='balanced'),
    'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),
    'Neural Network': MLPClassifier(random_state=42, max_iter=1000),
    'Naive Bayes': GaussianNB(),
    'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight='balanced')
}

if XGBOOST_AVAILABLE:
    algorithms['XGBoost'] = xgb.XGBClassifier(random_state=42, eval_metric='mlogloss')

# æµ‹è¯•æ‰€æœ‰ç®—æ³•å¹¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
results = {}
detailed_reports = {}

print("æµ‹è¯•å„ç§ç®—æ³•...")
print("="*80)

for name, clf in algorithms.items():
    try:
        # äº¤å‰éªŒè¯
        cv_scores = cross_val_score(clf, X_scaled, y_encoded, cv=cv, scoring='accuracy')
        
        # è®­ç»ƒå¹¶æµ‹è¯•
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        test_acc = accuracy_score(y_test, y_pred)
        
        # è½¬æ¢é¢„æµ‹ç»“æœå›åŸå§‹æ ‡ç­¾
        y_test_orig_current = label_encoder.inverse_transform(y_test)
        y_pred_orig = label_encoder.inverse_transform(y_pred)
        
        # ç”Ÿæˆè¯¦ç»†åˆ†ç±»æŠ¥å‘Š
        class_names = [f"{x}äºº" for x in sorted(label_encoder.classes_)]
        detailed_report = classification_report(
            y_test_orig_current, y_pred_orig, 
            target_names=class_names, 
            output_dict=True,
            zero_division=0
        )
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
        precision, recall, f1, support = precision_recall_fscore_support(
            y_test_orig_current, y_pred_orig, 
            labels=sorted(label_encoder.classes_),
            zero_division=0
        )
        
        results[name] = {
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'test_acc': test_acc,
            'model': clf,
            'precision_per_class': precision,
            'recall_per_class': recall,
            'f1_per_class': f1,
            'support_per_class': support
        }
        
        detailed_reports[name] = detailed_report
        
        # æ‰“å°è¯¦ç»†ç»“æœ
        print(f"\n{name} è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
        report_str = classification_report(
            y_test_orig_current, y_pred_orig, 
            target_names=class_names,
            zero_division=0
        )
        print(report_str)
        
        print(f"{name:20} CV: {cv_scores.mean():.4f}Â±{cv_scores.std():.4f} Test: {test_acc:.4f}")
        print("-"*60)
        
    except Exception as e:
        print(f"{name} å¤±è´¥: {e}")

# =====================
# 5. èšç±»ç®—æ³•æµ‹è¯• (æ–°å¢)
# =====================
print("\n5. èšç±»ç®—æ³•æµ‹è¯•...")
print("="*50)

# èšç±»ç®—æ³•å­—å…¸
clustering_algorithms = {
    'K-Means': KMeans(n_clusters=len(y.unique()), random_state=42, n_init=10),
    'Gaussian Mixture': GaussianMixture(n_components=len(y.unique()), random_state=42),
    'Agglomerative': AgglomerativeClustering(n_clusters=len(y.unique())),
    'Spectral Clustering': SpectralClustering(n_clusters=len(y.unique()), random_state=42),
    'DBSCAN': DBSCAN(eps=0.5, min_samples=5)
}

clustering_results = {}

print(f"çœŸå®NoCç±»åˆ«æ•°: {len(y.unique())}")
print(f"èšç±»ç›®æ ‡: {sorted(y.unique())}")

for name, clusterer in clustering_algorithms.items():
    try:
        print(f"\næµ‹è¯• {name}...")
        
        # æ‰§è¡Œèšç±»
        if name == 'DBSCAN':
            # DBSCANéœ€è¦è°ƒå‚
            cluster_labels = clusterer.fit_predict(X_scaled)
            n_clusters_found = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)
            n_noise = list(cluster_labels).count(-1)
            print(f"  DBSCANå‘ç° {n_clusters_found} ä¸ªèšç±»ï¼Œ{n_noise} ä¸ªå™ªå£°ç‚¹")
        else:
            cluster_labels = clusterer.fit_predict(X_scaled)
            n_clusters_found = len(set(cluster_labels))
        
        # è®¡ç®—èšç±»è¯„ä¼°æŒ‡æ ‡
        if len(set(cluster_labels)) > 1:  # ç¡®ä¿æœ‰å¤šä¸ªèšç±»
            ari = adjusted_rand_score(y_encoded, cluster_labels)
            nmi = normalized_mutual_info_score(y_encoded, cluster_labels)
            homogeneity = homogeneity_score(y_encoded, cluster_labels)
            completeness = completeness_score(y_encoded, cluster_labels)
            v_measure = v_measure_score(y_encoded, cluster_labels)
            
            # è½®å»“ç³»æ•°
            if len(set(cluster_labels)) > 1 and len(set(cluster_labels)) < len(cluster_labels):
                silhouette = silhouette_score(X_scaled, cluster_labels)
            else:
                silhouette = -1  # æ— æ³•è®¡ç®—
            
            clustering_results[name] = {
                'n_clusters_found': n_clusters_found,
                'ari': ari,
                'nmi': nmi,
                'homogeneity': homogeneity,
                'completeness': completeness,
                'v_measure': v_measure,
                'silhouette': silhouette,
                'cluster_labels': cluster_labels
            }
            
            print(f"  å‘ç°èšç±»æ•°: {n_clusters_found}")
            print(f"  è°ƒæ•´å…°å¾·æŒ‡æ•° (ARI): {ari:.4f}")
            print(f"  æ ‡å‡†åŒ–äº’ä¿¡æ¯ (NMI): {nmi:.4f}")
            print(f"  åŒè´¨æ€§: {homogeneity:.4f}")
            print(f"  å®Œæ•´æ€§: {completeness:.4f}")
            print(f"  V-measure: {v_measure:.4f}")
            print(f"  è½®å»“ç³»æ•°: {silhouette:.4f}")
            
        else:
            print(f"  {name} åªæ‰¾åˆ°ä¸€ä¸ªèšç±»ï¼Œè·³è¿‡è¯„ä¼°")
            
    except Exception as e:
        print(f"  {name} å¤±è´¥: {e}")

# =====================
# 6. æ¨¡å‹é›†æˆ (ä¿æŒåŸæœ‰é€»è¾‘)
# =====================
print("\n6. æ¨¡å‹é›†æˆ...")

# é€‰æ‹©top 3æ¨¡å‹è¿›è¡Œé›†æˆ
top_models = sorted(results.items(), key=lambda x: x[1]['cv_mean'], reverse=True)[:3]
print("Top 3 æ¨¡å‹:")
for name, result in top_models:
    print(f"  {name}: {result['cv_mean']:.4f}")

# åˆ›å»ºæŠ•ç¥¨åˆ†ç±»å™¨
voting_models = [(name, result['model']) for name, result in top_models]
ensemble_model = VotingClassifier(
    estimators=voting_models,
    voting='soft',
    weights=[3, 2, 1]
)

# è®­ç»ƒé›†æˆæ¨¡å‹
ensemble_model.fit(X_train, y_train)
y_pred_ensemble = ensemble_model.predict(X_test)
ensemble_acc = accuracy_score(y_test, y_pred_ensemble)

print(f"é›†æˆæ¨¡å‹æµ‹è¯•å‡†ç¡®ç‡: {ensemble_acc:.4f}")

# é›†æˆæ¨¡å‹çš„è¯¦ç»†æŠ¥å‘Š
y_pred_ensemble_orig = label_encoder.inverse_transform(y_pred_ensemble)
y_test_orig_ensemble = label_encoder.inverse_transform(y_test)

print(f"\né›†æˆæ¨¡å‹è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
class_names = [f"{x}äºº" for x in sorted(label_encoder.classes_)]
ensemble_report = classification_report(
    y_test_orig_ensemble, y_pred_ensemble_orig, 
    target_names=class_names,
    zero_division=0
)
print(ensemble_report)

# æ›´æ–°ç»“æœ
results['Ensemble'] = {
    'cv_mean': cross_val_score(ensemble_model, X_scaled, y_encoded, cv=cv, scoring='accuracy').mean(),
    'test_acc': ensemble_acc,
    'model': ensemble_model
}

# =====================
# 7. å¢å¼ºçš„å¯è§†åŒ–åˆ†æ
# =====================
print("\n7. å¢å¼ºçš„å¯è§†åŒ–åˆ†æ...")

# 7.1 æ¨¡å‹æ€§èƒ½æ¯”è¾ƒå›¾
plt.figure(figsize=(16, 10))
model_names = list(results.keys())
cv_scores = [results[name]['cv_mean'] for name in model_names]
test_scores = [results[name]['test_acc'] for name in model_names]

x = np.arange(len(model_names))
width = 0.35

bars1 = plt.bar(x - width/2, cv_scores, width, label='CV Score', alpha=0.8, color='skyblue')
bars2 = plt.bar(x + width/2, test_scores, width, label='Test Score', alpha=0.8, color='lightcoral')

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for i, (cv_score, test_score) in enumerate(zip(cv_scores, test_scores)):
    plt.text(i - width/2, cv_score + 0.01, f'{cv_score:.3f}', ha='center', va='bottom', fontsize=9)
    plt.text(i + width/2, test_score + 0.01, f'{test_score:.3f}', ha='center', va='bottom', fontsize=9)

plt.xlabel('æ¨¡å‹')
plt.ylabel('å‡†ç¡®ç‡')
plt.title('å„æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ')
plt.xticks(x, model_names, rotation=45, ha='right')
plt.legend()
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.savefig(os.path.join(PLOTS_DIR, 'model_comparison_enhanced.png'), dpi=300, bbox_inches='tight')
plt.close()

# 7.2 æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†æ€§èƒ½çƒ­å›¾
if len(results) > 2:
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()
    
    # é€‰æ‹©å‰6ä¸ªæ¨¡å‹
    top_6_models = list(results.keys())[:6]
    
    for idx, model_name in enumerate(top_6_models):
        if idx >= 6:
            break
            
        ax = axes[idx]
        
        if 'precision_per_class' in results[model_name]:
            # åˆ›å»ºæ€§èƒ½çŸ©é˜µ
            metrics = ['Precision', 'Recall', 'F1-Score']
            classes = [f"{x}äºº" for x in sorted(label_encoder.classes_)]
            
            perf_matrix = np.array([
                results[model_name]['precision_per_class'],
                results[model_name]['recall_per_class'], 
                results[model_name]['f1_per_class']
            ])
            
            im = ax.imshow(perf_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)
            
            # è®¾ç½®æ ‡ç­¾
            ax.set_xticks(range(len(classes)))
            ax.set_xticklabels(classes)
            ax.set_yticks(range(len(metrics)))
            ax.set_yticklabels(metrics)
            
            # æ·»åŠ æ•°å€¼
            for i in range(len(metrics)):
                for j in range(len(classes)):
                    text = ax.text(j, i, f'{perf_matrix[i, j]:.3f}', 
                                 ha="center", va="center", color="black", fontsize=8)
            
            ax.set_title(f'{model_name}')
        else:
            ax.text(0.5, 0.5, f'{model_name}\næ— è¯¦ç»†æŒ‡æ ‡', ha='center', va='center', transform=ax.transAxes)
            ax.set_xticks([])
            ax.set_yticks([])
    
    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(len(top_6_models), 6):
        axes[idx].set_visible(False)
    
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, 'model_performance_heatmap.png'), dpi=300, bbox_inches='tight')
    plt.close()

# 7.3 èšç±»ç»“æœå¯è§†åŒ–
if clustering_results:
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()
    
    # ä½¿ç”¨PCAé™ç»´åˆ°2Dè¿›è¡Œå¯è§†åŒ–
    from sklearn.decomposition import PCA
    pca = PCA(n_components=2, random_state=42)
    X_pca = pca.fit_transform(X_scaled)
    
    cluster_methods = list(clustering_results.keys())[:6]  # æœ€å¤šæ˜¾ç¤º6ä¸ªèšç±»æ–¹æ³•
    
    for idx, method in enumerate(cluster_methods):
        if idx >= 6:
            break
            
        ax = axes[idx]
        cluster_labels = clustering_results[method]['cluster_labels']
        
        # ç»˜åˆ¶èšç±»ç»“æœ
        scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7, s=30)
        ax.set_title(f'{method}\nARI: {clustering_results[method]["ari"]:.3f}, '
                    f'NMI: {clustering_results[method]["nmi"]:.3f}')
        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')
        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')
        ax.grid(True, alpha=0.3)
    
    # çœŸå®æ ‡ç­¾ä½œä¸ºå‚è€ƒ
    if len(cluster_methods) < 6:
        ax = axes[len(cluster_methods)]
        scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y_encoded, cmap='tab10', alpha=0.7, s=30)
        ax.set_title('çœŸå®NoCæ ‡ç­¾ (å‚è€ƒ)')
        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')
        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('NoC')
    
    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(len(cluster_methods) + 1, 6):
        axes[idx].set_visible(False)
    
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, 'clustering_results_pca.png'), dpi=300, bbox_inches='tight')
    plt.close()

# 7.4 èšç±»æ€§èƒ½è¯„ä¼°å¯¹æ¯”
if clustering_results:
    metrics = ['ari', 'nmi', 'homogeneity', 'completeness', 'v_measure', 'silhouette']
    methods = list(clustering_results.keys())
    
    # åˆ›å»ºè¯„ä¼°çŸ©é˜µ
    eval_matrix = np.zeros((len(methods), len(metrics)))
    for i, method in enumerate(methods):
        for j, metric in enumerate(metrics):
            eval_matrix[i, j] = clustering_results[method][metric]
    
    plt.figure(figsize=(12, 8))
    im = plt.imshow(eval_matrix, cmap='RdYlGn', aspect='auto', vmin=-1, vmax=1)
    
    # è®¾ç½®æ ‡ç­¾
    plt.xticks(range(len(metrics)), [m.upper() for m in metrics])
    plt.yticks(range(len(methods)), methods)
    
    # æ·»åŠ æ•°å€¼
    for i in range(len(methods)):
        for j in range(len(metrics)):
            text = plt.text(j, i, f'{eval_matrix[i, j]:.3f}', 
                           ha="center", va="center", 
                           color="white" if abs(eval_matrix[i, j]) > 0.5 else "black",
                           fontweight='bold')
    
    plt.title('èšç±»ç®—æ³•æ€§èƒ½è¯„ä¼°å¯¹æ¯”')
    plt.colorbar(im, label='è¯„ä¼°åˆ†æ•°')
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, 'clustering_evaluation_matrix.png'), dpi=300, bbox_inches='tight')
    plt.close()

# 7.5 æ··æ·†çŸ©é˜µå¯¹æ¯” - æœ€ä½³æ¨¡å‹
best_model_name = max(results.keys(), key=lambda x: results[x]['test_acc'])
best_predictions = results[best_model_name]['model'].predict(X_test)

y_test_display = label_encoder.inverse_transform(y_test)
best_predictions_display = label_encoder.inverse_transform(best_predictions)

plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_test_display, best_predictions_display)
class_names = [f"{x}äºº" for x in sorted(label_encoder.classes_)]

# è®¡ç®—å‡†ç¡®ç‡ç™¾åˆ†æ¯”
cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

# ç»˜åˆ¶æ··æ·†çŸ©é˜µ
sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues', 
           xticklabels=class_names, yticklabels=class_names,
           cbar_kws={'label': 'ç™¾åˆ†æ¯” (%)'})

# åœ¨æ¯ä¸ªæ ¼å­é‡Œæ·»åŠ ç»å¯¹æ•°é‡
for i in range(len(class_names)):
    for j in range(len(class_names)):
        plt.text(j + 0.5, i + 0.7, f'({cm[i, j]})', 
                ha='center', va='center', color='red', fontsize=10, fontweight='bold')

plt.title(f'{best_model_name} æ··æ·†çŸ©é˜µ\næ€»ä½“å‡†ç¡®ç‡: {results[best_model_name]["test_acc"]:.4f}')
plt.ylabel('çœŸå®æ ‡ç­¾ (NoC)')
plt.xlabel('é¢„æµ‹æ ‡ç­¾ (NoC)')
plt.tight_layout()
plt.savefig(os.path.join(PLOTS_DIR, 'confusion_matrix_best_enhanced.png'), dpi=300, bbox_inches='tight')
plt.close()

# 7.6 ç‰¹å¾é‡è¦æ€§åˆ†æ
if hasattr(results[best_model_name]['model'], 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': results[best_model_name]['model'].feature_importances_
    }).sort_values('importance', ascending=False)
    
    plt.figure(figsize=(14, 10))
    top_features = feature_importance.head(20)  # æ˜¾ç¤ºå‰20ä¸ªç‰¹å¾
    
    # åˆ›å»ºé¢œè‰²æ˜ å°„
    colors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))
    
    bars = plt.barh(range(len(top_features)), top_features['importance'], color=colors)
    plt.yticks(range(len(top_features)), top_features['feature'])
    plt.xlabel('ç‰¹å¾é‡è¦æ€§')
    plt.title(f'{best_model_name} ç‰¹å¾é‡è¦æ€§æ’å (å‰20ä½)')
    plt.grid(axis='x', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, importance) in enumerate(zip(bars, top_features['importance'])):
        plt.text(importance + 0.001, i, f'{importance:.4f}', 
                va='center', fontsize=8)
    
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, 'feature_importance_enhanced.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"\n{best_model_name} Top 15 é‡è¦ç‰¹å¾:")
    for idx, row in feature_importance.head(15).iterrows():
        print(f"  {row['feature']:35} {row['importance']:.6f}")

# =====================
# 8. ç»¼åˆæ€§èƒ½åˆ†æ
# =====================
print("\n8. ç»¼åˆæ€§èƒ½åˆ†æ...")

# 8.1 æœ‰ç›‘ç£å­¦ä¹  vs æ— ç›‘ç£å­¦ä¹ å¯¹æ¯”
print("\næœ‰ç›‘ç£å­¦ä¹  vs æ— ç›‘ç£å­¦ä¹ æ€§èƒ½å¯¹æ¯”:")
print("="*60)

print("æœ‰ç›‘ç£å­¦ä¹ æœ€ä½³ç»“æœ:")
print(f"  æœ€ä½³æ¨¡å‹: {best_model_name}")
print(f"  æµ‹è¯•å‡†ç¡®ç‡: {results[best_model_name]['test_acc']:.4f}")
print(f"  äº¤å‰éªŒè¯å‡†ç¡®ç‡: {results[best_model_name]['cv_mean']:.4f}Â±{results[best_model_name]['cv_std']:.4f}")

if clustering_results:
    print("\næ— ç›‘ç£å­¦ä¹ æœ€ä½³ç»“æœ:")
    best_clustering = max(clustering_results.items(), key=lambda x: x[1]['ari'])
    best_clustering_name, best_clustering_result = best_clustering
    print(f"  æœ€ä½³èšç±»: {best_clustering_name}")
    print(f"  è°ƒæ•´å…°å¾·æŒ‡æ•° (ARI): {best_clustering_result['ari']:.4f}")
    print(f"  æ ‡å‡†åŒ–äº’ä¿¡æ¯ (NMI): {best_clustering_result['nmi']:.4f}")
    print(f"  V-measure: {best_clustering_result['v_measure']:.4f}")

# 8.2 å„NoCç±»åˆ«è¯¦ç»†åˆ†æ
print(f"\nå„NoCç±»åˆ«è¯¦ç»†åˆ†æ (åŸºäº{best_model_name}):")
print("="*60)

best_model_results = results[best_model_name]
if 'precision_per_class' in best_model_results:
    class_labels = sorted(label_encoder.classes_)
    
    analysis_df = pd.DataFrame({
        'NoC': [f"{x}äºº" for x in class_labels],
        'Precision': best_model_results['precision_per_class'],
        'Recall': best_model_results['recall_per_class'],
        'F1-Score': best_model_results['f1_per_class'],
        'Support': best_model_results['support_per_class'].astype(int)
    })
    
    print(analysis_df.to_string(index=False, float_format='%.4f'))
    
    # æ‰¾å‡ºè¡¨ç°æœ€å¥½å’Œæœ€å·®çš„ç±»åˆ«
    best_f1_idx = np.argmax(best_model_results['f1_per_class'])
    worst_f1_idx = np.argmin(best_model_results['f1_per_class'])
    
    print(f"\nè¡¨ç°æœ€ä½³ç±»åˆ«: {class_labels[best_f1_idx]}äºº (F1: {best_model_results['f1_per_class'][best_f1_idx]:.4f})")
    print(f"è¡¨ç°æœ€å·®ç±»åˆ«: {class_labels[worst_f1_idx]}äºº (F1: {best_model_results['f1_per_class'][worst_f1_idx]:.4f})")

# =====================
# 9. ä¿å­˜ç»“æœ
# =====================
print("\n9. ä¿å­˜ç»“æœ...")

# ä¿å­˜ç‰¹å¾æ•°æ®
df_features.to_csv(os.path.join(DATA_DIR, 'q1_features_enhanced_v4.csv'), index=False, encoding='utf-8-sig')

# åº”ç”¨æœ€ä½³æ¨¡å‹åˆ°æ‰€æœ‰æ•°æ®
best_model_final = results[best_model_name]['model']
y_pred_all_encoded = best_model_final.predict(X_scaled)
y_pred_all = label_encoder.inverse_transform(y_pred_all_encoded)
df_features['predicted_noc'] = y_pred_all

# ä¿å­˜é¢„æµ‹ç»“æœ
df_features.to_csv(os.path.join(DATA_DIR, 'q1_predictions_enhanced_v4.csv'), index=False, encoding='utf-8-sig')

# ä¿å­˜è¯¦ç»†çš„æ€§èƒ½æ€»ç»“
detailed_summary = {
    'analysis_metadata': {
        'version': '4.0',
        'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
        'best_model': best_model_name,
        'best_test_accuracy': float(results[best_model_name]['test_acc']),
        'feature_count': len(feature_cols),
        'sample_count': len(df_features),
        'noc_distribution': y_original.value_counts().sort_index().to_dict()
    },
    'supervised_learning_results': {
        name: {
            'cv_mean': float(result['cv_mean']), 
            'cv_std': float(result['cv_std']),
            'test_acc': float(result['test_acc']),
            'precision_per_class': result.get('precision_per_class', []).tolist() if hasattr(result.get('precision_per_class', []), 'tolist') else result.get('precision_per_class', []),
            'recall_per_class': result.get('recall_per_class', []).tolist() if hasattr(result.get('recall_per_class', []), 'tolist') else result.get('recall_per_class', []),
            'f1_per_class': result.get('f1_per_class', []).tolist() if hasattr(result.get('f1_per_class', []), 'tolist') else result.get('f1_per_class', []),
            'support_per_class': result.get('support_per_class', []).tolist() if hasattr(result.get('support_per_class', []), 'tolist') else result.get('support_per_class', [])
        } 
        for name, result in results.items() if name != 'Ensemble'  # Ensembleæ¨¡å‹å¯¹è±¡æ— æ³•åºåˆ—åŒ–
    },
    'unsupervised_learning_results': {
        name: {
            'n_clusters_found': int(result['n_clusters_found']),
            'ari': float(result['ari']),
            'nmi': float(result['nmi']),
            'homogeneity': float(result['homogeneity']),
            'completeness': float(result['completeness']),
            'v_measure': float(result['v_measure']),
            'silhouette': float(result['silhouette'])
        }
        for name, result in clustering_results.items()
    } if clustering_results else {},
    'detailed_classification_reports': detailed_reports
}

with open(os.path.join(DATA_DIR, 'q1_detailed_summary_v4.json'), 'w', encoding='utf-8') as f:
    json.dump(detailed_summary, f, ensure_ascii=False, indent=2)

# =====================
# 10. æœ€ç»ˆæŠ¥å‘Š
# =====================
print("\n" + "="*80)
print("å¢å¼ºç‰ˆ NoC è¯†åˆ«ç³»ç»Ÿ v4.0 - æœ€ç»ˆæŠ¥å‘Š")
print("="*80)

print(f"\nğŸ“Š æ•°æ®æ¦‚å†µ:")
print(f"   â€¢ æ ·æœ¬æ€»æ•°: {len(df_features)}")
print(f"   â€¢ NoCåˆ†å¸ƒ: {dict(y_original.value_counts().sort_index())}")
print(f"   â€¢ ç‰¹å¾æ€»æ•°: {len(feature_cols)}")

print(f"\nğŸ† æœ‰ç›‘ç£å­¦ä¹ æœ€ä½³ç»“æœ:")
print(f"   â€¢ æœ€ä½³æ¨¡å‹: {best_model_name}")
print(f"   â€¢ æµ‹è¯•é›†å‡†ç¡®ç‡: {results[best_model_name]['test_acc']:.4f}")
print(f"   â€¢ äº¤å‰éªŒè¯: {results[best_model_name]['cv_mean']:.4f}Â±{results[best_model_name]['cv_std']:.4f}")

if clustering_results:
    best_clustering = max(clustering_results.items(), key=lambda x: x[1]['ari'])
    print(f"\nğŸ” æ— ç›‘ç£å­¦ä¹ æœ€ä½³ç»“æœ:")
    print(f"   â€¢ æœ€ä½³èšç±»: {best_clustering[0]}")
    print(f"   â€¢ ARIæŒ‡æ•°: {best_clustering[1]['ari']:.4f}")
    print(f"   â€¢ NMIæŒ‡æ•°: {best_clustering[1]['nmi']:.4f}")

print(f"\nğŸ“ˆ å„ç±»åˆ«æœ€ä½³è¡¨ç° (åŸºäº{best_model_name}):")
if 'precision_per_class' in results[best_model_name]:
    class_labels = sorted(label_encoder.classes_)
    for i, noc in enumerate(class_labels):
        precision = results[best_model_name]['precision_per_class'][i]
        recall = results[best_model_name]['recall_per_class'][i]
        f1 = results[best_model_name]['f1_per_class'][i]
        support = results[best_model_name]['support_per_class'][i]
        print(f"   â€¢ {noc}äºº: P={precision:.3f}, R={recall:.3f}, F1={f1:.3f} (n={int(support)})")

print(f"\nğŸ’¾ ä¿å­˜çš„æ–‡ä»¶:")
print(f"   â€¢ å¢å¼ºç‰¹å¾æ•°æ®: q1_features_enhanced_v4.csv")
print(f"   â€¢ é¢„æµ‹ç»“æœ: q1_predictions_enhanced_v4.csv")
print(f"   â€¢ è¯¦ç»†æ€§èƒ½æŠ¥å‘Š: q1_detailed_summary_v4.json")
print(f"   â€¢ å›¾è¡¨ç›®å½•: {PLOTS_DIR}/")

print(f"\nğŸ“Š ç”Ÿæˆçš„å¯è§†åŒ–:")
print(f"   â€¢ æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾")
print(f"   â€¢ è¯¦ç»†æ€§èƒ½çƒ­å›¾")
print(f"   â€¢ èšç±»ç»“æœPCAå¯è§†åŒ–")
print(f"   â€¢ èšç±»è¯„ä¼°çŸ©é˜µ")
print(f"   â€¢ å¢å¼ºæ··æ·†çŸ©é˜µ")
print(f"   â€¢ ç‰¹å¾é‡è¦æ€§åˆ†æ")

print(f"\nğŸ¯ ä¸»è¦æ”¹è¿›:")
print(f"   âœ“ è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š - æ¯ä¸ªæ¨¡å‹å¯¹å„NoCçš„ç²¾ç¡®è¡¨ç°")
print(f"   âœ“ å¤šç§èšç±»ç®—æ³• - K-Means, GMM, å±‚æ¬¡èšç±»ç­‰")
print(f"   âœ“ æœ‰ç›‘ç£ vs æ— ç›‘ç£å¯¹æ¯”åˆ†æ")
print(f"   âœ“ å¢å¼ºçš„å¯è§†åŒ– - æ€§èƒ½çƒ­å›¾ã€PCAèšç±»å›¾ç­‰")
print(f"   âœ“ ç»¼åˆæ€§èƒ½è¯„ä¼° - ARI, NMI, V-measureç­‰æŒ‡æ ‡")

print(f"\nâœ… åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨å’ŒæŠ¥å‘Šã€‚")
print("="*80)