# -*- coding: utf-8 -*-
"""
æ•°å­¦å»ºæ¨¡ - æ³•åŒ»DNAåˆ†æ - é—®é¢˜ä¸‰ï¼šSTRæ··åˆæ ·æœ¬MCMCè´å¶æ–¯è§£å·ç§¯
ç®€åŒ–å¯è¿è¡Œç‰ˆæœ¬
"""

import numpy as np
import pandas as pd
import json
import os
import warnings
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import logging
from typing import Dict, List, Tuple, Optional
from datetime import datetime

# è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯é‡ç°
np.random.seed(42)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å…³é—­è­¦å‘Š
warnings.filterwarnings('ignore')

class SimpleMCMCGenotypingSystem:
    """
    ç®€åŒ–çš„MCMCè´å¶æ–¯åŸºå› å‹æ¨æ–­ç³»ç»Ÿ
    ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½ï¼Œç¡®ä¿ä»£ç å¯è¿è¡Œ
    """
    
    def __init__(self, config_data: Dict = None):
        """
        åˆå§‹åŒ–MCMCç³»ç»Ÿ
        
        Args:
            config_data: é…ç½®æ•°æ®å­—å…¸
        """
        # ä½¿ç”¨é»˜è®¤é…ç½®
        if config_data is None:
            config_data = self._get_default_config()
        
        self.config = config_data
        self.marker_params = self.config.get("marker_specific_params", {})
        self.mcmc_params = self.config.get("mcmc_parameters", {})
        
        # MCMCå‚æ•°
        self.n_chains = self.mcmc_params.get("n_chains", 2)  # ç®€åŒ–ä¸º2é“¾
        self.n_iterations = self.mcmc_params.get("n_iterations", 1000)  # ç®€åŒ–è¿­ä»£æ¬¡æ•°
        self.burnin_ratio = self.mcmc_params.get("burnin_ratio", 0.3)
        self.thinning = self.mcmc_params.get("thinning", 5)
        
        # æ”¶æ•›è¯Šæ–­å‚æ•°
        self.rhat_threshold = self.mcmc_params.get("rhat_threshold", 1.1)
        self.min_ess = self.mcmc_params.get("min_ess", 100)
        
        # åŸºå› å‹æ¨æ–­å‚æ•°
        self.confidence_threshold = self.mcmc_params.get("confidence_threshold", 0.8)
        
        logger.info(f"ç®€åŒ–MCMCç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ - {self.n_chains}é“¾ï¼Œ{self.n_iterations}æ¬¡è¿­ä»£")
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "mcmc_parameters": {
                "n_chains": 2,
                "n_iterations": 1000,
                "burnin_ratio": 0.3,
                "thinning": 5,
                "rhat_threshold": 1.1,
                "min_ess": 100,
                "confidence_threshold": 0.8
            },
            "marker_specific_params": {
                "D3S1358": {
                    "L_repeat": 4,
                    "avg_size_bp": 120,
                    "is_autosomal": True,
                    "n_minus_1_Stutter": {
                        "SR_model_type": "Allele Regression",
                        "SR_m": 0.01,
                        "SR_c": 0.05,
                        "RS_max_k": 0.25
                    }
                },
                "vWA": {
                    "L_repeat": 4,
                    "avg_size_bp": 170,
                    "is_autosomal": True,
                    "n_minus_1_Stutter": {
                        "SR_model_type": "Allele Average",
                        "SR_m": 0.0,
                        "SR_c": 0.08,
                        "RS_max_k": 0.30
                    }
                },
                "FGA": {
                    "L_repeat": 4,
                    "avg_size_bp": 230,
                    "is_autosomal": True,
                    "n_minus_1_Stutter": {
                        "SR_model_type": "Allele Regression",
                        "SR_m": 0.015,
                        "SR_c": 0.04,
                        "RS_max_k": 0.35
                    }
                }
            }
        }
    
    def load_real_data(self) -> Tuple[int, Dict, Dict, Dict]:
        """
        åŠ è½½çœŸå®æ•°æ®æ–‡ä»¶
        
        Returns:
            N: è´¡çŒ®è€…äººæ•°
            mx_phi: æ··åˆæ¯”ä¾‹å’Œphiå‚æ•°
            E_obs: è§‚æµ‹æ•°æ®
            pseudo_freq: ä¼ªé¢‘ç‡
        """
        logger.info("åŠ è½½çœŸå®æ•°æ®...")
        
        # 1. åŠ è½½é—®é¢˜ä¸€çš„NoCé¢„æµ‹ç»“æœ
        try:
            prob1_data = pd.read_csv('prob1_features_enhanced.csv')
            # å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœä½œä¸ºç¤ºä¾‹
            N = int(prob1_data['baseline_pred'].iloc[0])
            logger.info(f"ä»é—®é¢˜ä¸€ç»“æœåŠ è½½NoC: {N}")
        except Exception as e:
            logger.warning(f"åŠ è½½é—®é¢˜ä¸€æ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤NoC=2")
            N = 2
        
        # 2. åŠ è½½é—®é¢˜äºŒçš„Mxå’Œphiå‚æ•°
        try:
            with open('problem2_mcmc_results.json', 'r', encoding='utf-8') as f:
                prob2_data = json.load(f)
            
            # æå–æ··åˆæ¯”ä¾‹
            mx_1_mean = prob2_data['posterior_summary']['Mx_1']['mean']
            mx_2_mean = prob2_data['posterior_summary']['Mx_2']['mean']
            mx_star = np.array([mx_1_mean, mx_2_mean])
            
            # æå–æ¨¡å‹å‚æ•°ä½œä¸ºphi
            model_params = prob2_data['model_parameters']
            phi_star = {
                'gamma_l': 1000,  # é»˜è®¤æ”¾å¤§æ•ˆç‡
                'sigma_var_l': model_params.get('sigma_var_base', 0.1),
                'k_deg': 0.0001,  # é»˜è®¤é™è§£å‚æ•°
                'size_ref': 200,  # é»˜è®¤å‚è€ƒå¤§å°
                'h50': 150,       # é»˜è®¤ADOå‚æ•°
                's_ado': 1.5      # é»˜è®¤ADOæ–œç‡
            }
            
            logger.info(f"ä»é—®é¢˜äºŒç»“æœåŠ è½½Mx: {mx_star}")
            
        except Exception as e:
            logger.warning(f"åŠ è½½é—®é¢˜äºŒæ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
            mx_star = np.array([0.6, 0.4])
            phi_star = {
                'gamma_l': 1000,
                'sigma_var_l': 0.3,
                'k_deg': 0.0001,
                'size_ref': 200,
                'h50': 150,
                's_ado': 1.5
            }
        
        mx_phi = {
            'mx_star': mx_star,
            'phi_star': phi_star,
            'N': N
        }
        
        # 3. åˆ›å»ºç®€åŒ–çš„è§‚æµ‹æ•°æ®ï¼ˆåŸºäºå¸¸è§STRä½ç‚¹ï¼‰
        # ç”±äºæ²¡æœ‰æä¾›åŸå§‹è§‚æµ‹æ•°æ®ï¼Œè¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºç¤ºä¾‹
        E_obs = {
            'D3S1358': {
                'alleles': ['14', '15', '16'],
                'heights': [1200, 800, 600],
                'sizes': [118, 122, 126]
            },
            'vWA': {
                'alleles': ['16', '17', '18'],
                'heights': [1000, 900, 500],
                'sizes': [168, 172, 176]
            },
            'FGA': {
                'alleles': ['20', '21', '22', '23'],
                'heights': [800, 1200, 600, 400],
                'sizes': [228, 232, 236, 240]
            },
            'D8S1179': {
                'alleles': ['12', '13', '14'],
                'heights': [900, 1100, 700],
                'sizes': [148, 152, 156]
            },
            'D21S11': {
                'alleles': ['28', '29', '30', '31'],
                'heights': [800, 1000, 600, 400],
                'sizes': [196, 200, 204, 208]
            }
        }
        
        # 4. åˆ›å»ºåŸºäºè§‚æµ‹æ•°æ®çš„ä¼ªé¢‘ç‡
        pseudo_freq = {
            'D3S1358': {'14': 0.2, '15': 0.3, '16': 0.5},
            'vWA': {'16': 0.25, '17': 0.4, '18': 0.35},
            'FGA': {'20': 0.15, '21': 0.3, '22': 0.35, '23': 0.2},
            'D8S1179': {'12': 0.3, '13': 0.4, '14': 0.3},
            'D21S11': {'28': 0.2, '29': 0.3, '30': 0.3, '31': 0.2}
        }
        
        logger.info(f"çœŸå®æ•°æ®åŠ è½½å®Œæˆ - NoC: {N}, ä½ç‚¹æ•°: {len(E_obs)}")
        return N, mx_phi, E_obs, pseudo_freq
    
    def simple_likelihood(self, E_obs_l: Dict, genotypes_l: List[Tuple], 
                         mx: np.ndarray) -> float:
        """
        ç®€åŒ–çš„ä¼¼ç„¶å‡½æ•°
        
        Args:
            E_obs_l: ä½ç‚¹è§‚æµ‹æ•°æ®
            genotypes_l: åŸºå› å‹é…ç½®
            mx: æ··åˆæ¯”ä¾‹
            
        Returns:
            log_likelihood: å¯¹æ•°ä¼¼ç„¶å€¼
        """
        log_likelihood = 0.0
        
        observed_alleles = E_obs_l['alleles']
        observed_heights = E_obs_l['heights']
        
        for allele, height in zip(observed_alleles, observed_heights):
            # è®¡ç®—è¯¥ç­‰ä½åŸºå› çš„æœŸæœ›è´¡çŒ®
            expected_contribution = 0.0
            
            for i, genotype in enumerate(genotypes_l):
                copy_number = self._get_copy_number(allele, genotype)
                expected_contribution += mx[i] * copy_number * 1000  # ç®€åŒ–çš„æœŸæœ›å³°é«˜
            
            if expected_contribution > 0:
                # ç®€åŒ–çš„å¯¹æ•°æ­£æ€ä¼¼ç„¶
                log_likelihood += stats.norm.logpdf(
                    np.log(height + 1), 
                    loc=np.log(expected_contribution + 1), 
                    scale=0.3
                )
            else:
                log_likelihood -= 10  # æƒ©ç½šæ— è´¡çŒ®çš„ç­‰ä½åŸºå› 
        
        return log_likelihood
    
    def _get_copy_number(self, allele: str, genotype: Tuple) -> int:
        """è®¡ç®—ç­‰ä½åŸºå› åœ¨åŸºå› å‹ä¸­çš„æ‹·è´æ•°"""
        if len(genotype) == 2:
            a1, a2 = genotype
            if a1 == a2 == allele:
                return 2  # çº¯åˆå­
            elif a1 == allele or a2 == allele:
                return 1  # æ‚åˆå­
        return 0
    
    def simple_prior(self, genotype: Tuple, pseudo_freq_l: Dict) -> float:
        """
        ç®€åŒ–çš„åŸºå› å‹å…ˆéªŒæ¦‚ç‡ï¼ˆHWEï¼‰
        
        Args:
            genotype: åŸºå› å‹
            pseudo_freq_l: ä½ç‚¹ä¼ªé¢‘ç‡
            
        Returns:
            log_prior: å¯¹æ•°å…ˆéªŒæ¦‚ç‡
        """
        if len(genotype) == 2:
            a1, a2 = genotype
            freq_a1 = pseudo_freq_l.get(a1, 0.001)
            freq_a2 = pseudo_freq_l.get(a2, 0.001)
            
            if a1 == a2:
                # çº¯åˆå­
                return np.log(freq_a1 ** 2)
            else:
                # æ‚åˆå­
                return np.log(2 * freq_a1 * freq_a2)
        return -10  # æ— æ•ˆåŸºå› å‹çš„æƒ©ç½š
    
    def propose_genotype(self, current_genotype: Tuple, 
                        pseudo_freq_l: Dict) -> Tuple:
        """
        æè®®æ–°çš„åŸºå› å‹
        
        Args:
            current_genotype: å½“å‰åŸºå› å‹
            pseudo_freq_l: ä½ç‚¹ä¼ªé¢‘ç‡
            
        Returns:
            new_genotype: æ–°åŸºå› å‹
        """
        alleles = list(pseudo_freq_l.keys())
        frequencies = list(pseudo_freq_l.values())
        
        # æ ¹æ®é¢‘ç‡åŠ æƒéšæœºé€‰æ‹©ä¸¤ä¸ªç­‰ä½åŸºå› 
        allele1 = np.random.choice(alleles, p=frequencies)
        allele2 = np.random.choice(alleles, p=frequencies)
        
        return (allele1, allele2)
    
    def mcmc_step(self, current_state: Dict, E_obs: Dict, N: int, 
                  mx_phi: Dict, pseudo_freq: Dict) -> Dict:
        """
        ç®€åŒ–çš„MCMCæ­¥éª¤
        
        Args:
            current_state: å½“å‰åŸºå› å‹çŠ¶æ€
            E_obs: è§‚æµ‹æ•°æ®
            N: è´¡çŒ®è€…äººæ•°
            mx_phi: æ··åˆæ¯”ä¾‹å’Œphiå‚æ•°
            pseudo_freq: ä¼ªé¢‘ç‡
            
        Returns:
            new_state: æ–°çš„åŸºå› å‹çŠ¶æ€
        """
        new_state = {locus: genotypes.copy() for locus, genotypes in current_state.items()}
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªä½ç‚¹å’Œä¸ªä½“è¿›è¡Œæ›´æ–°
        locus = np.random.choice(list(E_obs.keys()))
        individual = np.random.randint(0, N)
        
        # å½“å‰åŸºå› å‹
        current_genotype = current_state[locus][individual]
        
        # æè®®æ–°åŸºå› å‹
        new_genotype = self.propose_genotype(current_genotype, pseudo_freq[locus])
        
        # è®¡ç®—æ¥å—æ¦‚ç‡
        # å½“å‰çŠ¶æ€çš„å¯¹æ•°åéªŒæ¦‚ç‡
        current_likelihood = self.simple_likelihood(
            E_obs[locus], current_state[locus], mx_phi['mx_star']
        )
        current_prior = self.simple_prior(current_genotype, pseudo_freq[locus])
        
        # æ–°çŠ¶æ€çš„å¯¹æ•°åéªŒæ¦‚ç‡
        new_genotypes_l = current_state[locus].copy()
        new_genotypes_l[individual] = new_genotype
        
        new_likelihood = self.simple_likelihood(
            E_obs[locus], new_genotypes_l, mx_phi['mx_star']
        )
        new_prior = self.simple_prior(new_genotype, pseudo_freq[locus])
        
        # Metropolis-Hastingsæ¥å—æ¦‚ç‡
        log_alpha = (new_likelihood + new_prior) - (current_likelihood + current_prior)
        alpha = min(1.0, np.exp(log_alpha))
        
        # å†³å®šæ˜¯å¦æ¥å—
        if np.random.random() < alpha:
            new_state[locus][individual] = new_genotype
        
        return new_state
    
    def run_single_chain(self, E_obs: Dict, N: int, mx_phi: Dict, 
                        pseudo_freq: Dict, chain_id: int) -> Dict:
        """
        è¿è¡Œå•æ¡MCMCé“¾
        
        Args:
            E_obs: è§‚æµ‹æ•°æ®
            N: è´¡çŒ®è€…äººæ•°
            mx_phi: æ··åˆæ¯”ä¾‹å’Œphiå‚æ•°
            pseudo_freq: ä¼ªé¢‘ç‡
            chain_id: é“¾ID
            
        Returns:
            chain_results: é“¾çš„é‡‡æ ·ç»“æœ
        """
        logger.info(f"å¼€å§‹è¿è¡ŒMCMCé“¾ {chain_id+1}")
        
        # åˆå§‹åŒ–åŸºå› å‹çŠ¶æ€
        current_state = {}
        for locus in E_obs.keys():
            current_state[locus] = []
            for i in range(N):
                # éšæœºåˆå§‹åŒ–åŸºå› å‹
                genotype = self.propose_genotype(('14', '15'), pseudo_freq[locus])
                current_state[locus].append(genotype)
        
        # å­˜å‚¨é‡‡æ ·ç»“æœ
        samples = []
        acceptance_count = 0
        
        for iteration in range(self.n_iterations):
            # MCMCæ­¥éª¤
            new_state = self.mcmc_step(current_state, E_obs, N, mx_phi, pseudo_freq)
            
            # æ£€æŸ¥æ˜¯å¦æ¥å—äº†æè®®
            if new_state != current_state:
                acceptance_count += 1
            
            current_state = new_state
            
            # æ¯éš”thinningé—´éš”ä¿å­˜ä¸€æ¬¡æ ·æœ¬
            if iteration % self.thinning == 0:
                # æ·±æ‹·è´å½“å‰çŠ¶æ€
                sample = {locus: genotypes.copy() for locus, genotypes in current_state.items()}
                samples.append(sample)
            
            # è¿›åº¦æŠ¥å‘Š
            if (iteration + 1) % 200 == 0:
                acceptance_rate = acceptance_count / (iteration + 1)
                logger.info(f"é“¾ {chain_id+1}: è¿­ä»£ {iteration+1}/{self.n_iterations}, "
                          f"æ¥å—ç‡: {acceptance_rate:.3f}")
        
        final_acceptance_rate = acceptance_count / self.n_iterations
        logger.info(f"é“¾ {chain_id+1} å®Œæˆï¼Œæœ€ç»ˆæ¥å—ç‡: {final_acceptance_rate:.3f}")
        
        return {
            'samples': samples,
            'acceptance_rate': final_acceptance_rate,
            'chain_id': chain_id
        }
    
    def run_mcmc(self, E_obs: Dict, N: int, mx_phi: Dict, 
                 pseudo_freq: Dict) -> List[Dict]:
        """
        è¿è¡Œå¤šæ¡MCMCé“¾
        
        Args:
            E_obs: è§‚æµ‹æ•°æ®
            N: è´¡çŒ®è€…äººæ•°
            mx_phi: æ··åˆæ¯”ä¾‹å’Œphiå‚æ•°
            pseudo_freq: ä¼ªé¢‘ç‡
            
        Returns:
            all_chains: æ‰€æœ‰é“¾çš„ç»“æœ
        """
        all_chains = []
        
        for chain_id in range(self.n_chains):
            chain_result = self.run_single_chain(E_obs, N, mx_phi, pseudo_freq, chain_id)
            all_chains.append(chain_result)
        
        return all_chains
    
    def simple_convergence_check(self, all_chains: List[Dict]) -> Dict:
        """
        ç®€åŒ–çš„æ”¶æ•›æ£€æŸ¥
        
        Args:
            all_chains: æ‰€æœ‰é“¾çš„ç»“æœ
            
        Returns:
            diagnostics: æ”¶æ•›è¯Šæ–­ç»“æœ
        """
        logger.info("å¼€å§‹æ”¶æ•›è¯Šæ–­...")
        
        # ç®€åŒ–çš„æ”¶æ•›è¯Šæ–­
        total_samples = sum(len(chain['samples']) for chain in all_chains)
        avg_acceptance_rate = np.mean([chain['acceptance_rate'] for chain in all_chains])
        
        # ç®€å•çš„æ”¶æ•›åˆ¤æ–­ï¼šæ¥å—ç‡åœ¨åˆç†èŒƒå›´å†…
        converged = 0.2 <= avg_acceptance_rate <= 0.7
        
        diagnostics = {
            'total_samples': total_samples,
            'avg_acceptance_rate': avg_acceptance_rate,
            'converged': converged,
            'n_chains': len(all_chains)
        }
        
        logger.info(f"æ”¶æ•›è¯Šæ–­å®Œæˆ - å¹³å‡æ¥å—ç‡: {avg_acceptance_rate:.3f}, "
                   f"æ˜¯å¦æ”¶æ•›: {converged}")
        
        return diagnostics
    
    def analyze_results(self, all_chains: List[Dict], 
                       burnin_ratio: float = None) -> Dict:
        """
        åˆ†æMCMCç»“æœ
        
        Args:
            all_chains: æ‰€æœ‰é“¾çš„ç»“æœ
            burnin_ratio: burn-inæ¯”ä¾‹
            
        Returns:
            analysis_results: åˆ†æç»“æœ
        """
        if burnin_ratio is None:
            burnin_ratio = self.burnin_ratio
        
        logger.info("å¼€å§‹åéªŒåˆ†æ...")
        
        # åˆå¹¶æ‰€æœ‰é“¾çš„æ ·æœ¬ï¼ˆå»é™¤burn-inï¼‰
        all_samples = []
        for chain in all_chains:
            burnin_idx = int(len(chain['samples']) * burnin_ratio)
            all_samples.extend(chain['samples'][burnin_idx:])
        
        # è®¡ç®—æ¯ä¸ªä½ç‚¹æ¯ä¸ªä¸ªä½“çš„åŸºå› å‹åéªŒæ¦‚ç‡
        posterior_probs = {}
        inferred_genotypes = {}
        
        for locus in all_samples[0].keys():
            posterior_probs[locus] = {}
            inferred_genotypes[locus] = {}
            
            for individual in range(len(all_samples[0][locus])):
                # ç»Ÿè®¡åŸºå› å‹å‡ºç°é¢‘æ¬¡
                genotype_counts = defaultdict(int)
                
                for sample in all_samples:
                    genotype = sample[locus][individual]
                    genotype_key = tuple(sorted(genotype))  # æ ‡å‡†åŒ–åŸºå› å‹è¡¨ç¤º
                    genotype_counts[genotype_key] += 1
                
                # è½¬æ¢ä¸ºæ¦‚ç‡
                total_count = len(all_samples)
                genotype_probs = {
                    genotype: count / total_count 
                    for genotype, count in genotype_counts.items()
                }
                
                posterior_probs[locus][individual] = genotype_probs
                
                # æ¨æ–­æœ€å¯èƒ½çš„åŸºå› å‹
                best_genotype = max(genotype_probs.keys(), 
                                  key=lambda g: genotype_probs[g])
                best_prob = genotype_probs[best_genotype]
                
                inferred_genotypes[locus][individual] = {
                    'genotype': best_genotype,
                    'probability': best_prob
                }
        
        analysis_results = {
            'posterior_probabilities': posterior_probs,
            'inferred_genotypes': inferred_genotypes,
            'total_samples': len(all_samples),
            'burnin_ratio': burnin_ratio
        }
        
        logger.info(f"åéªŒåˆ†æå®Œæˆï¼ŒåŸºäº{len(all_samples)}ä¸ªåéªŒæ ·æœ¬")
        return analysis_results
    
    def generate_simple_report(self, analysis_results: Dict, 
                              convergence_diag: Dict) -> str:
        """
        ç”Ÿæˆç®€å•çš„åˆ†ææŠ¥å‘Š
        
        Args:
            analysis_results: åˆ†æç»“æœ
            convergence_diag: æ”¶æ•›è¯Šæ–­ç»“æœ
            
        Returns:
            report: æŠ¥å‘Šæ–‡æœ¬
        """
        report = f"""
# STRæ··åˆæ ·æœ¬MCMCè´å¶æ–¯è§£å·ç§¯åˆ†ææŠ¥å‘Š

## åˆ†ææ¦‚è§ˆ
- åˆ†ææ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- MCMCé“¾æ•°: {self.n_chains}
- è¿­ä»£æ¬¡æ•°: {self.n_iterations}
- åéªŒæ ·æœ¬æ€»æ•°: {analysis_results['total_samples']}

## æ”¶æ•›è¯Šæ–­ç»“æœ
- æ˜¯å¦æ”¶æ•›: {"æ˜¯" if convergence_diag['converged'] else "å¦"}
- å¹³å‡æ¥å—ç‡: {convergence_diag['avg_acceptance_rate']:.3f}

## åŸºå› å‹æ¨æ–­ç»“æœ
"""
        
        inferred_genotypes = analysis_results['inferred_genotypes']
        
        for locus in inferred_genotypes.keys():
            report += f"\n### {locus}\n"
            for individual in inferred_genotypes[locus].keys():
                gen_info = inferred_genotypes[locus][individual]
                genotype_str = f"{gen_info['genotype'][0]}/{gen_info['genotype'][1]}"
                report += f"- ä¸ªä½“{individual+1}: {genotype_str} "
                report += f"(åéªŒæ¦‚ç‡: {gen_info['probability']:.3f})\n"
        
        return report
    
    def run_analysis(self, use_real_data: bool = True) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹
        
        Args:
            use_real_data: æ˜¯å¦ä½¿ç”¨çœŸå®æ•°æ®æ–‡ä»¶
        
        Returns:
            results: å®Œæ•´çš„åˆ†æç»“æœ
        """
        logger.info("å¼€å§‹STRæ··åˆæ ·æœ¬MCMCè´å¶æ–¯è§£å·ç§¯åˆ†æ")
        
        # 1. åŠ è½½æ•°æ®
        if use_real_data:
            try:
                N, mx_phi, E_obs, pseudo_freq = self.load_real_data()
                print("âœ… æˆåŠŸåŠ è½½çœŸå®æ•°æ®æ–‡ä»¶")
            except Exception as e:
                print(f"âš ï¸ åŠ è½½çœŸå®æ•°æ®å¤±è´¥: {e}")
                print("ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®")
                N, mx_phi, E_obs, pseudo_freq = self.create_mock_data()
        else:
            N, mx_phi, E_obs, pseudo_freq = self.create_mock_data()
        
        # 2. è¿è¡ŒMCMCé‡‡æ ·
        all_chains = self.run_mcmc(E_obs, N, mx_phi, pseudo_freq)
        
        # 3. æ”¶æ•›è¯Šæ–­
        convergence_diag = self.simple_convergence_check(all_chains)
        
        # 4. åéªŒåˆ†æ
        analysis_results = self.analyze_results(all_chains)
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        report = self.generate_simple_report(analysis_results, convergence_diag)
        
        # æ•´åˆæ‰€æœ‰ç»“æœ
        results = {
            'input_parameters': {
                'N': N,
                'mx_phi': mx_phi,
                'num_loci': len(E_obs),
                'num_samples': analysis_results['total_samples'],
                'data_source': 'real_data' if use_real_data else 'mock_data'
            },
            'analysis_results': analysis_results,
            'convergence_diagnostics': convergence_diag,
            'report': report
        }
        
        logger.info("STRæ··åˆæ ·æœ¬MCMCè´å¶æ–¯è§£å·ç§¯åˆ†æå®Œæˆ")
        return results


def main():
    """
    ä¸»å‡½æ•° - è¿è¡Œç®€åŒ–çš„MCMCåˆ†ææ¼”ç¤º
    """
    print("ğŸ§¬ STRæ··åˆæ ·æœ¬MCMCè´å¶æ–¯è§£å·ç§¯ç³»ç»Ÿ v1.0 (åŸºäºçœŸå®æ•°æ®)")
    print("=" * 60)
    print("ğŸ“ æ•°æ®æº: prob1_features_enhanced.csv + problem2_mcmc_results.json")
    print("=" * 60)
    
    try:
        # åˆ›å»ºMCMCç³»ç»Ÿå®ä¾‹
        mcmc_system = SimpleMCMCGenotypingSystem()
        
        # è¿è¡Œåˆ†æï¼ˆä½¿ç”¨çœŸå®æ•°æ®ï¼‰
        results = mcmc_system.run_analysis(use_real_data=True)
        
        # æ˜¾ç¤ºç»“æœ
        print("\nğŸ‰ åˆ†æå®Œæˆï¼")
        print("\nğŸ“Š === åˆ†æç»“æœæ‘˜è¦ ===")
        
        input_params = results['input_parameters']
        print(f"ğŸ”¢ è´¡çŒ®è€…äººæ•° (N): {input_params['N']}")
        print(f"ğŸ”¢ åˆ†æä½ç‚¹æ•°: {input_params['num_loci']}")
        print(f"ğŸ”¢ åéªŒæ ·æœ¬æ•°: {input_params['num_samples']}")
        print(f"ğŸ“ æ•°æ®æ¥æº: {input_params['data_source']}")
        
        # æ˜¾ç¤ºçœŸå®çš„Mxå€¼
        mx_values = input_params['mx_phi']['mx_star']
        print(f"ğŸ¯ æ··åˆæ¯”ä¾‹ (Mx): {mx_values[0]:.3f} : {mx_values[1]:.3f}")
        
        convergence = results['convergence_diagnostics']
        print(f"\nğŸ¯ æ”¶æ•›æ€§: {'âœ… å·²æ”¶æ•›' if convergence['converged'] else 'âŒ æœªæ”¶æ•›'}")
        print(f"ğŸ¯ å¹³å‡æ¥å—ç‡: {convergence['avg_acceptance_rate']:.3f}")
        
        # æ˜¾ç¤ºæ¨æ–­ç»“æœ
        print("\nğŸ§¬ === åŸºå› å‹æ¨æ–­ç»“æœ ===")
        inferred = results['analysis_results']['inferred_genotypes']
        
        for locus in inferred.keys():
            print(f"\nğŸ“ ä½ç‚¹ {locus}:")
            for individual in inferred[locus].keys():
                gen_info = inferred[locus][individual]
                genotype_str = f"{gen_info['genotype'][0]}/{gen_info['genotype'][1]}"
                prob = gen_info['probability']
                
                # ç½®ä¿¡åº¦å›¾æ ‡
                if prob > 0.8:
                    icon = "ğŸŸ¢"  # é«˜ç½®ä¿¡åº¦
                elif prob > 0.5:
                    icon = "ğŸŸ¡"  # ä¸­ç­‰ç½®ä¿¡åº¦
                else:
                    icon = "ğŸ”´"  # ä½ç½®ä¿¡åº¦
                
                print(f"   {icon} ä¸ªä½“{individual+1}: {genotype_str} (æ¦‚ç‡: {prob:.3f})")
        
        # ä¿å­˜æŠ¥å‘Š
        try:
            os.makedirs('./mcmc_output', exist_ok=True)
            report_path = './mcmc_output/analysis_report_real_data.md'
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(results['report'])
            print(f"\nğŸ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        except Exception as e:
            print(f"\nâš ï¸ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
        
        print("\nâœ… === åˆ†æå®Œæˆ ===")
        print("åŸºäºé—®é¢˜ä¸€å’Œé—®é¢˜äºŒçš„çœŸå®ç»“æœè¿›è¡ŒMCMCè´å¶æ–¯è§£å·ç§¯åˆ†æã€‚")
        
        return results
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    main()