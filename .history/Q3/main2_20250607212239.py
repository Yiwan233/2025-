# -*- coding: utf-8 -*-
"""
é—®é¢˜ä¸‰ä½¿ç”¨ç¤ºä¾‹è„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨Q3å¢å¼ºåŸºå› å‹æ¨æ–­ç³»ç»Ÿ
"""

import sys
import os
import numpy as np
import pandas as pd
from Q3_Enhanced_Genotype_Inference import analyze_single_sample_q3, analyze_all_samples_q3, Q3EnhancedPipeline

def example_1_single_sample_analysis():
    """ç¤ºä¾‹1ï¼šå•æ ·æœ¬åŸºå› å‹æ¨æ–­"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹1ï¼šå•æ ·æœ¬åŸºå› å‹æ¨æ–­åˆ†æ")
    print("="*60)
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    att1_path = "é™„ä»¶1ï¼šä¸åŒäººæ•°çš„STRå›¾è°±æ•°æ®.csv"
    att2_path = "é™„ä»¶2ï¼šæ··åˆSTRå›¾è°±æ•°æ®.csv"
    att3_path = "é™„ä»¶3ï¼šå„ä¸ªè´¡çŒ®è€…çš„åŸºå› å‹.csv"
    q1_model_path = "noc_optimized_random_forest_model.pkl"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(att1_path) and not os.path.exists(att2_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°é™„ä»¶1æˆ–é™„ä»¶2æ–‡ä»¶")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹")
        return
    
    # é¦–å…ˆæŸ¥çœ‹å¯ç”¨çš„æ ·æœ¬
    data_file = att2_path if os.path.exists(att2_path) else att1_path
    try:
        df_samples = pd.read_csv(data_file, encoding='utf-8')
        available_samples = df_samples['Sample File'].unique()
        print(f"å¯ç”¨çš„æ ·æœ¬ID ({len(available_samples)}ä¸ª):")
        for i, sample_id in enumerate(available_samples[:10], 1):
            print(f"  {i}. {sample_id}")
        if len(available_samples) > 10:
            print(f"  ... è¿˜æœ‰{len(available_samples)-10}ä¸ªæ ·æœ¬")
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªæ ·æœ¬è¿›è¡Œåˆ†æ
        if len(available_samples) > 0:
            target_sample = available_samples[0]
            print(f"\né€‰æ‹©æ ·æœ¬ '{target_sample}' è¿›è¡ŒåŸºå› å‹æ¨æ–­åˆ†æ...")
            
            # æ‰§è¡Œåˆ†æ
            result = analyze_single_sample_q3(
                sample_id=target_sample,
                att1_or_att2_path=data_file,
                q1_model_path=q1_model_path if os.path.exists(q1_model_path) else None,
                att3_path=att3_path if os.path.exists(att3_path) else None
            )
            
            # æ˜¾ç¤ºç»“æœ
            print_analysis_result_q3(result)
            
        else:
            print("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ ·æœ¬")
            
    except Exception as e:
        print(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")

def example_2_batch_analysis():
    """ç¤ºä¾‹2ï¼šæ‰¹é‡åŸºå› å‹æ¨æ–­ï¼ˆå‰3ä¸ªæ ·æœ¬ï¼‰"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹2ï¼šæ‰¹é‡åŸºå› å‹æ¨æ–­åˆ†æ")
    print("="*60)
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    att2_path = "é™„ä»¶2ï¼šæ··åˆSTRå›¾è°±æ•°æ®.csv"
    att3_path = "é™„ä»¶3ï¼šå„ä¸ªè´¡çŒ®è€…çš„åŸºå› å‹.csv"
    q1_model_path = "noc_optimized_random_forest_model.pkl"
    
    if not os.path.exists(att2_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°é™„ä»¶2æ–‡ä»¶ - {att2_path}")
        return
    
    try:
        # æ‰¹é‡åˆ†æå‰3ä¸ªæ ·æœ¬
        all_results = analyze_all_samples_q3(
            att1_or_att2_path=att2_path,
            q1_model_path=q1_model_path if os.path.exists(q1_model_path) else None,
            att3_path=att3_path if os.path.exists(att3_path) else None,
            max_samples=3  # åªåˆ†æå‰3ä¸ªæ ·æœ¬
        )
        
        print(f"\næ‰¹é‡åˆ†æå®Œæˆï¼Œå…±åˆ†æäº† {len(all_results)} ä¸ªæ ·æœ¬")
        
        # æ˜¾ç¤ºæ±‡æ€»ç»“æœ
        print("\næ±‡æ€»ç»“æœ:")
        for sample_id, result in all_results.items():
            print(f"\næ ·æœ¬: {sample_id}")
            print_analysis_result_q3(result, brief=True)
            
    except Exception as e:
        print(f"æ‰¹é‡åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")

def example_3_programmatic_usage():
    """ç¤ºä¾‹3ï¼šç¨‹åºåŒ–ä½¿ç”¨æ¥å£"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹3ï¼šç¨‹åºåŒ–ä½¿ç”¨æ¥å£")
    print("="*60)
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    att2_path = "é™„ä»¶2ï¼šæ··åˆSTRå›¾è°±æ•°æ®.csv"
    att3_path = "é™„ä»¶3ï¼šå„ä¸ªè´¡çŒ®è€…çš„åŸºå› å‹.csv"
    q1_model_path = "noc_optimized_random_forest_model.pkl"
    
    if not os.path.exists(att2_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°é™„ä»¶2æ–‡ä»¶ - {att2_path}")
        return
    
    try:
        # åˆå§‹åŒ–Q3å¢å¼ºæµæ°´çº¿
        pipeline = Q3EnhancedPipeline(
            q1_model_path if os.path.exists(q1_model_path) else None,
            att3_path if os.path.exists(att3_path) else None
        )
        
        # åŠ è½½æ•°æ®
        print("åŠ è½½é™„ä»¶2æ•°æ®...")
        pipeline.load_data(att2_path=att2_path)
        print("æ•°æ®åŠ è½½å®Œæˆ")
        
        # è¯»å–æ ·æœ¬æ•°æ®
        df_samples = pd.read_csv(att2_path, encoding='utf-8')
        available_samples = df_samples['Sample File'].unique()
        
        if len(available_samples) > 0:
            sample_id = available_samples[0]
            sample_data = df_samples[df_samples['Sample File'] == sample_id]
            
            print(f"\nåˆ†ææ ·æœ¬: {sample_id}")
            
            # æ‰§è¡Œåˆ†æ
            result = pipeline.analyze_single_sample(sample_id, sample_data)
            
            # ä¿å­˜ç»“æœ
            output_file = f"./example_q3_result_{sample_id}.json"
            pipeline.save_results(result, output_file)
            print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
            # ç»˜åˆ¶å›¾è¡¨
            pipeline.plot_results(result, "./example_q3_plots")
            print("å›¾è¡¨å·²ä¿å­˜åˆ°: ./example_q3_plots/")
            
            # æ˜¾ç¤ºç»“æœ
            print_analysis_result_q3(result)
            
    except Exception as e:
        print(f"ç¨‹åºåŒ–ä½¿ç”¨è¿‡ç¨‹å‡ºé”™: {e}")

def example_4_performance_analysis():
    """ç¤ºä¾‹4ï¼šåŸºå› å‹æ¨æ–­æ€§èƒ½åˆ†æ"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹4ï¼šåŸºå› å‹æ¨æ–­æ€§èƒ½åˆ†æ")
    print("="*60)
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    att2_path = "é™„ä»¶2ï¼šæ··åˆSTRå›¾è°±æ•°æ®.csv"
    att3_path = "é™„ä»¶3ï¼šå„ä¸ªè´¡çŒ®è€…çš„åŸºå› å‹.csv"
    q1_model_path = "noc_optimized_random_forest_model.pkl"
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    if not all([os.path.exists(f) for f in [att2_path, att3_path]]):
        print("é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„æ•°æ®æ–‡ä»¶")
        print("æ€§èƒ½åˆ†æéœ€è¦é™„ä»¶2å’Œé™„ä»¶3")
        return
    
    try:
        # åˆå§‹åŒ–æµæ°´çº¿
        pipeline = Q3EnhancedPipeline(
            q1_model_path if os.path.exists(q1_model_path) else None,
            att3_path
        )
        
        # åŠ è½½æ•°æ®
        pipeline.load_data(att2_path=att2_path)
        
        # è·å–æœ‰çœŸå®åŸºå› å‹çš„æ ·æœ¬
        available_samples = pipeline.att3_processor.get_available_samples()
        print(f"æœ‰çœŸå®åŸºå› å‹çš„æ ·æœ¬æ•°: {len(available_samples)}")
        
        if len(available_samples) > 0:
            # åˆ†æç¬¬ä¸€ä¸ªæœ‰çœŸå®åŸºå› å‹çš„æ ·æœ¬
            target_sample = available_samples[0]
            print(f"\nåˆ†ææ ·æœ¬: {target_sample}")
            
            # è¯»å–æ ·æœ¬æ•°æ®
            df_samples = pd.read_csv(att2_path, encoding='utf-8')
            sample_data = df_samples[df_samples['Sample File'] == target_sample]
            
            if not sample_data.empty:
                # æ‰§è¡Œå®Œæ•´åˆ†æ
                result = pipeline.analyze_single_sample(target_sample, sample_data)
                
                # è¯¦ç»†æ˜¾ç¤ºæ€§èƒ½è¯„ä¼°ç»“æœ
                if result['evaluation_results']:
                    print_detailed_performance_analysis(result['evaluation_results'])
                
                # æ˜¾ç¤ºåŸºå› å‹æ¨æ–­è¯¦æƒ…
                print_genotype_inference_details(result)
                
            else:
                print(f"æ ·æœ¬ {target_sample} åœ¨é™„ä»¶2ä¸­æœªæ‰¾åˆ°å¯¹åº”æ•°æ®")
        
    except Exception as e:
        print(f"æ€§èƒ½åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")

def print_analysis_result_q3(result: Dict, brief=False):
    """æ‰“å°Q3åˆ†æç»“æœ"""
    print(f"--- åŸºå› å‹æ¨æ–­åˆ†æç»“æœ ---")
    print(f"æ ·æœ¬ID: {result['sample_id']}")
    print(f"é¢„æµ‹NoC: {result['predicted_noc']} (ç½®ä¿¡åº¦: {result['noc_confidence']:.3f})")
    print(f"è®¡ç®—æ—¶é—´: {result['computation_time']:.1f}ç§’")
    print(f"è§‚æµ‹ä½ç‚¹æ•°: {len(result['observed_loci'])}")
    
    if result['mcmc_results'] is not None:
        mcmc_results = result['mcmc_results']
        print(f"MCMCæ··åˆæ¯”ä¾‹æ¥å—ç‡: {mcmc_results['acceptance_rate_mx']:.3f}")
        print(f"MCMCåŸºå› å‹æ¥å—ç‡: {mcmc_results['acceptance_rate_gt']:.3f}")
        print(f"MCMCæ”¶æ•›: {'æ˜¯' if mcmc_results['converged'] else 'å¦'}")
        print(f"æœ‰æ•ˆæ ·æœ¬æ•°: {mcmc_results['n_samples']}")
        
        if not brief:
            # æ˜¾ç¤ºåŸºå› å‹æ¨æ–­æ‘˜è¦
            posterior_summary = result['posterior_summary']
            if posterior_summary and result['observed_loci']:
                print(f"\nåŸºå› å‹æ¨æ–­ç»“æœæ‘˜è¦:")
                
                # æ˜¾ç¤ºå‰ä¸¤ä¸ªä½ç‚¹çš„ç»“æœ
                for locus in result['observed_loci'][:2]:
                    if locus in posterior_summary:
                        print(f"\nä½ç‚¹ {locus}:")
                        locus_summary = posterior_summary[locus]
                        
                        for contributor, contrib_data in locus_summary.items():
                            if 'mode_genotype' in contrib_data:
                                mode_gt = contrib_data['mode_genotype']
                                mode_prob = contrib_data['mode_probability']
                                print(f"  {contributor}: {mode_gt[0]},{mode_gt[1]} "
                                      f"(æ¦‚ç‡: {mode_prob:.3f})")
            
            # æ˜¾ç¤ºæ€§èƒ½è¯„ä¼°ç»“æœ
            if result['evaluation_results'] and 'overall_summary' in result['evaluation_results']:
                eval_summary = result['evaluation_results']['overall_summary']
                print(f"\næ€§èƒ½è¯„ä¼°ç»“æœ:")
                
                if 'genotype_concordance_rate' in eval_summary:
                    gcr = eval_summary['genotype_concordance_rate']
                    grade = eval_summary.get('performance_grade', 'N/A')
                    print(f"  åŸºå› å‹ä¸€è‡´æ€§ç‡: {gcr:.3f}")
                    print(f"  æ€§èƒ½ç­‰çº§: {grade}")
                
                if 'allele_concordance_rate' in eval_summary:
                    acr = eval_summary['allele_concordance_rate']
                    print(f"  ç­‰ä½åŸºå› ä¸€è‡´æ€§ç‡: {acr:.3f}")
    else:
        print("âš ï¸  æ— æœ‰æ•ˆå³°æ•°æ®ï¼ŒMCMCæœªæ‰§è¡Œ")

def print_detailed_performance_analysis(evaluation_results: Dict):
    """æ‰“å°è¯¦ç»†çš„æ€§èƒ½åˆ†æç»“æœ"""
    print(f"\n{'='*50}")
    print("è¯¦ç»†æ€§èƒ½åˆ†æç»“æœ")
    print(f"{'='*50}")
    
    # æ€»ä½“æ€§èƒ½æ‘˜è¦
    if 'overall_summary' in evaluation_results:
        summary = evaluation_results['overall_summary']
        print(f"\nğŸ“Š æ€»ä½“æ€§èƒ½æŒ‡æ ‡:")
        
        if 'genotype_concordance_rate' in summary:
            gcr = summary['genotype_concordance_rate']
            grade = summary.get('performance_grade', 'N/A')
            print(f"   åŸºå› å‹ä¸€è‡´æ€§ç‡: {gcr:.4f} ({gcr*100:.2f}%)")
            print(f"   æ€§èƒ½ç­‰çº§: {grade}")
        
        if 'allele_concordance_rate' in summary:
            acr = summary['allele_concordance_rate']
            print(f"   ç­‰ä½åŸºå› ä¸€è‡´æ€§ç‡: {acr:.4f} ({acr*100:.2f}%)")
        
        if 'avg_locus_exact_match_rate' in summary:
            avg_locus = summary['avg_locus_exact_match_rate']
            print(f"   å¹³å‡ä½ç‚¹ç²¾ç¡®åŒ¹é…ç‡: {avg_locus:.4f}")
        
        if 'avg_contributor_exact_match_rate' in summary:
            avg_contrib = summary['avg_contributor_exact_match_rate']
            print(f"   å¹³å‡è´¡çŒ®è€…ç²¾ç¡®åŒ¹é…ç‡: {avg_contrib:.4f}")
    
    # ä½ç‚¹ç‰¹å¼‚æ€§æ€§èƒ½
    if 'locus_specific' in evaluation_results:
        locus_perf = evaluation_results['locus_specific']
        print(f"\nğŸ“ˆ ä½ç‚¹ç‰¹å¼‚æ€§æ€§èƒ½:")
        print(f"{'ä½ç‚¹':<12} {'ç²¾ç¡®åŒ¹é…ç‡':<12} {'éƒ¨åˆ†åŒ¹é…ç‡':<12} {'é”™è¯¯åŒ¹é…ç‡':<12}")
        print("-" * 50)
        
        for locus, perf in locus_perf.items():
            if 'exact_match_rate' in perf:
                exact_rate = perf['exact_match_rate']
                partial_rate = perf.get('partial_match_rate', 0)
                mismatch_rate = perf.get('mismatch_rate', 0)
                print(f"{locus:<12} {exact_rate:<12.3f} {partial_rate:<12.3f} {mismatch_rate:<12.3f}")
    
    # è´¡çŒ®è€…ç‰¹å¼‚æ€§æ€§èƒ½
    if 'contributor_specific' in evaluation_results:
        contrib_perf = evaluation_results['contributor_specific']
        print(f"\nğŸ‘¥ è´¡çŒ®è€…ç‰¹å¼‚æ€§æ€§èƒ½:")
        print(f"{'è´¡çŒ®è€…':<12} {'ç²¾ç¡®åŒ¹é…ç‡':<12} {'éƒ¨åˆ†åŒ¹é…ç‡':<12} {'é”™è¯¯åŒ¹é…ç‡':<12}")
        print("-" * 50)
        
        for contributor, perf in contrib_perf.items():
            if 'exact_match_rate' in perf:
                exact_rate = perf['exact_match_rate']
                partial_rate = perf.get('partial_match_rate', 0)
                mismatch_rate = perf.get('mismatch_rate', 0)
                print(f"{contributor:<12} {exact_rate:<12.3f} {partial_rate:<12.3f} {mismatch_rate:<12.3f}")

def print_genotype_inference_details(result: Dict):
    """æ‰“å°åŸºå› å‹æ¨æ–­è¯¦ç»†ä¿¡æ¯"""
    print(f"\n{'='*50}")
    print("åŸºå› å‹æ¨æ–­è¯¦ç»†ä¿¡æ¯")
    print(f"{'='*50}")
    
    posterior_summary = result['posterior_summary']
    observed_loci = result['observed_loci']
    
    if not posterior_summary or not observed_loci:
        print("æ— åŸºå› å‹æ¨æ–­ç»“æœ")
        return
    
    print(f"\næ¨æ–­çš„åŸºå› å‹åˆ†å¸ƒ:")
    
    for locus in observed_loci:
        if locus in posterior_summary and locus != 'mcmc_quality':
            print(f"\nğŸ§¬ ä½ç‚¹ {locus}:")
            locus_summary = posterior_summary[locus]
            
            for contributor, contrib_data in locus_summary.items():
                if 'mode_genotype' not in contrib_data:
                    continue
                
                mode_gt = contrib_data['mode_genotype']
                mode_prob = contrib_data['mode_probability']
                total_samples = contrib_data.get('total_samples', 0)
                
                print(f"  {contributor}:")
                print(f"    æœ€å¯èƒ½åŸºå› å‹: {mode_gt[0]},{mode_gt[1]} (æ¦‚ç‡: {mode_prob:.3f})")
                print(f"    æ ·æœ¬æ•°: {total_samples}")
                
                # æ˜¾ç¤º95%å¯ä¿¡é›†åˆ
                if 'credible_set_95' in contrib_data:
                    credible_set = contrib_data['credible_set_95']
                    print(f"    95%å¯ä¿¡é›†åˆ:")
                    for gt, prob in credible_set[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                        print(f"      {gt[0]},{gt[1]}: {prob:.3f}")
                    if len(credible_set) > 3:
                        print(f"      ... è¿˜æœ‰{len(credible_set)-3}ä¸ªåŸºå› å‹")

def create_synthetic_test_data_q3():
    """åˆ›å»ºQ3çš„åˆæˆæµ‹è¯•æ•°æ®"""
    print("\n" + "="*60)
    print("åˆ›å»ºQ3åˆæˆæµ‹è¯•æ•°æ®")
    print("="*60)
    
    np.random.seed(42)
    
    # åˆ›å»ºé™„ä»¶2æ ·å¼çš„æ··åˆSTRæ•°æ®
    sample_data = []
    markers = ['D3S1358', 'vWA', 'FGA', 'D8S1179', 'D21S11']
    
    for i, sample_id in enumerate([f"Mix_Sample_{j+1}" for j in range(3)], 1):
        for marker in markers:
            # æ¨¡æ‹Ÿ2-3äººæ··åˆæ ·æœ¬
            n_alleles = np.random.randint(3, 6)  # æ¯ä¸ªä½ç‚¹3-5ä¸ªç­‰ä½åŸºå› 
            
            for allele_idx in range(n_alleles):
                allele_num = np.random.randint(12, 20)
                allele = str(allele_num) if np.random.random() > 0.2 else f"{allele_num}.3"
                
                size = 120 + allele_num * 4 + np.random.normal(0, 1)
                height = np.random.lognormal(np.log(800), 0.6)
                
                sample_data.append({
                    'Sample File': sample_id,
                    'Marker': marker,
                    f'Allele {allele_idx+1}': allele,
                    f'Size {allele_idx+1}': size,
                    f'Height {allele_idx+1}': height
                })
    
    # å¡«å……ç©ºåˆ—
    df_synthetic_att2 = pd.DataFrame(sample_data)
    
    # æ·»åŠ ç©ºçš„Allele/Size/Heightåˆ—
    for i in range(1, 101):
        if f'Allele {i}' not in df_synthetic_att2.columns:
            df_synthetic_att2[f'Allele {i}'] = np.nan
        if f'Size {i}' not in df_synthetic_att2.columns:
            df_synthetic_att2[f'Size {i}'] = np.nan
        if f'Height {i}' not in df_synthetic_att2.columns:
            df_synthetic_att2[f'Height {i}'] = np.nan
    
    # é‡æ–°æ’åˆ—åˆ—é¡ºåº
    cols = ['Sample File', 'Marker']
    for i in range(1, 101):
        cols.extend([f'Allele {i}', f'Size {i}', f'Height {i}'])
    
    df_synthetic_att2 = df_synthetic_att2.reindex(columns=cols)
    
    # ä¿å­˜åˆæˆé™„ä»¶2
    att2_path = "åˆæˆé™„ä»¶2.csv"
    df_synthetic_att2.to_csv(att2_path, index=False, encoding='utf-8-sig')
    
    # åˆ›å»ºå¯¹åº”çš„é™„ä»¶3ï¼ˆçœŸå®åŸºå› å‹ï¼‰
    genotype_data = []
    for sample_id in [f"Mix_Sample_{j+1}" for j in range(3)]:
        n_contributors = np.random.randint(2, 4)  # 2-3ä¸ªè´¡çŒ®è€…
        
        for contributor_id in range(1, n_contributors + 1):
            for marker in markers:
                # ç”ŸæˆçœŸå®åŸºå› å‹
                allele1 = str(np.random.randint(12, 20))
                allele2 = str(np.random.randint(12, 20))
                
                genotype_data.append({
                    'Sample': sample_id,
                    'Contributor': f'P{contributor_id}',
                    'Marker': marker,
                    'Allele 1': allele1,
                    'Allele 2': allele2
                })
    
    df_synthetic_att3 = pd.DataFrame(genotype_data)
    att3_path = "åˆæˆé™„ä»¶3.csv"
    df_synthetic_att3.to_csv(att3_path, index=False, encoding='utf-8-sig')
    
    print(f"åˆæˆé™„ä»¶2å·²ä¿å­˜åˆ°: {att2_path}")
    print(f"åˆæˆé™„ä»¶3å·²ä¿å­˜åˆ°: {att3_path}")
    print(f"åŒ…å« {len(df_synthetic_att2['Sample File'].unique())} ä¸ªæ··åˆæ ·æœ¬")
    print(f"æ¶µç›– {len(markers)} ä¸ªSTRä½ç‚¹")
    print(f"åŒ…å« {len(df_synthetic_att3)} ä¸ªçœŸå®åŸºå› å‹è®°å½•")
    
    return att2_path, att3_path

def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("Q3å¢å¼ºåŸºå› å‹æ¨æ–­ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹")
    print("åŸºäºQ1éšæœºæ£®æ—ç‰¹å¾å·¥ç¨‹ + Q2 MGM-RFæ–¹æ³• + åŸºå› å‹åŒ¹é…è¯„ä¼°")
    print("="*80)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®æ•°æ®
    att2_path = "é™„ä»¶2ï¼šæ··åˆSTRå›¾è°±æ•°æ®.csv"
    att3_path = "é™„ä»¶3ï¼šå„ä¸ªè´¡çŒ®è€…çš„åŸºå› å‹.csv"
    
    if not os.path.exists(att2_path) or not os.path.exists(att3_path):
        print(f"æ²¡æœ‰æ‰¾åˆ°å¿…è¦æ–‡ä»¶:")
        if not os.path.exists(att2_path):
            print(f"  ç¼ºå°‘: {att2_path}")
        if not os.path.exists(att3_path):
            print(f"  ç¼ºå°‘: {att3_path}")
        
        print("æ˜¯å¦è¦åˆ›å»ºåˆæˆæµ‹è¯•æ•°æ®ï¼Ÿ(y/n): ", end="")
        
        choice = input().strip().lower()
        if choice == 'y':
            synthetic_att2, synthetic_att3 = create_synthetic_test_data_q3()
            print(f"\nè¯·å°†åˆæˆæ•°æ®é‡å‘½åä¸º:")
            print(f"  {synthetic_att2} -> {att2_path}")
            print(f"  {synthetic_att3} -> {att3_path}")
            print("ç„¶åé‡æ–°è¿è¡Œæ­¤è„šæœ¬")
            return
        else:
            print("ç¨‹åºé€€å‡º")
            return
    
    # è¿è¡Œç¤ºä¾‹
    try:
        # ç¤ºä¾‹1ï¼šå•æ ·æœ¬åŸºå› å‹æ¨æ–­
        example_1_single_sample_analysis()
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        print(f"\næ˜¯å¦ç»§ç»­è¿è¡Œå…¶ä»–ç¤ºä¾‹ï¼Ÿ(y/n): ", end="")
        if input().strip().lower() != 'y':
            return
        
        # ç¤ºä¾‹2ï¼šæ‰¹é‡åˆ†æ
        example_2_batch_analysis()
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        print(f"\næ˜¯å¦ç»§ç»­è¿è¡Œç¨‹åºåŒ–ç¤ºä¾‹ï¼Ÿ(y/n): ", end="")
        if input().strip().lower() != 'y':
            return
        
        # ç¤ºä¾‹3ï¼šç¨‹åºåŒ–ä½¿ç”¨
        example_3_programmatic_usage()
        
        # ç¤ºä¾‹4ï¼šæ€§èƒ½åˆ†æ
        print(f"\næ˜¯å¦æ¼”ç¤ºæ€§èƒ½åˆ†æï¼Ÿ(y/n): ", end="")
        if input().strip().lower() == 'y':
            example_4_performance_analysis()
        
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
    except Exception as e:
        print(f"\nç¤ºä¾‹è¿è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\n{'='*80}")
    print("æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("æ›´å¤šè¯¦ç»†ç”¨æ³•è¯·å‚è€ƒ Q3_Enhanced_Genotype_Inference.py")
    print("ä¸»è¦ç‰¹ç‚¹:")
    print("â€¢ é›†æˆQ1çš„RFECVç‰¹å¾é€‰æ‹©å’Œéšæœºæ£®æ—NoCé¢„æµ‹")
    print("â€¢ é‡‡ç”¨Q2çš„MGM-MåŸºå› å‹è¾¹ç¼˜åŒ–MCMCæ–¹æ³•")
    print("â€¢ ç»“åˆé™„ä»¶3çš„å·²çŸ¥åŸºå› å‹ä¿¡æ¯è¿›è¡Œæ¨æ–­")
    print("â€¢ æä¾›è¯¦ç»†çš„åŸºå› å‹åŒ¹é…å‡†ç¡®æ€§è¯„ä¼°")
    print("â€¢ æ”¯æŒå¤šé“¾MCMCæ”¶æ•›æ€§è¯Šæ–­")
    print("â€¢ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å’Œæ€§èƒ½æŠ¥å‘Š")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()