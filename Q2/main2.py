# -*- coding: utf-8 -*-
"""
æ•°å­¦å»ºæ¨¡ - æ³•åŒ»DNAåˆ†æ - é—®é¢˜2ï¼šæ··åˆæ¯”ä¾‹æ¨æ–­ (ä¿®æ­£ç‰ˆ)

ä»£ç åç§°: P2_MCMC_Corrected_V10
ç‰ˆæœ¬: V10.2 - ä¿®æ­£æ··åˆæ¯”ä¾‹è§£æç‰ˆæœ¬
æ—¥æœŸ: 2025-06-06
æè¿°: åŸºäºMCMCçš„æ··åˆæ¯”ä¾‹(Mx)å’Œé™è§£å‚æ•°(Î¸)æ¨æ–­
     æ­£ç¡®è§£æé™„ä»¶1ä¸­Sample Fileçš„è´¡çŒ®è€…IDå’Œæ··åˆæ¯”ä¾‹
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.special import loggamma, gammaln
import json
import os
import warnings
from typing import Dict, List, Tuple, Optional, Any, Union
import time
from collections import defaultdict
import itertools
from math import comb
import re

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå¿½ç•¥è­¦å‘Š
plt.rcParams['font.sans-serif'] = ["Arial Unicode MS"]
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')

def parse_sample_file_name(sample_file: str) -> Optional[Dict]:
    """
    æ­£ç¡®è§£æSample Fileåç§°ä¸­çš„è´¡çŒ®è€…IDå’Œæ··åˆæ¯”ä¾‹
    
    æ ¹æ®é™„ä»¶1ä¸­çš„å‘½åè§„åˆ™:
    "A02_RD14-0003-40_41-1;4-M3S30-0.075IP-Q4.0_001.5sec.fsa"
    å…¶ä¸­40_41-1;4è¡¨ç¤ºè´¡çŒ®è€…IDä¸º40ã€41ï¼Œæ··åˆæ¯”ä¾‹ä¸º1:4
    
    Args:
        sample_file: æ ·æœ¬æ–‡ä»¶å
        
    Returns:
        è§£æç»“æœå­—å…¸ï¼ŒåŒ…å«è´¡çŒ®è€…æ•°é‡ã€IDã€æ··åˆæ¯”ä¾‹ç­‰ä¿¡æ¯
    """
    # ç§»é™¤å¼•å·
    file_name = sample_file.replace('"', '').strip()
    
    # æ¨¡å¼1: ä¸¤äººæ··åˆæ ·æœ¬ - è´¡çŒ®è€…ID1_è´¡çŒ®è€…ID2-æ¯”ä¾‹1;æ¯”ä¾‹2
    match2 = re.search(r'-(\d+)_(\d+)-(\d+);(\d+)-', file_name)
    if match2:
        contributor1_id = int(match2.group(1))
        contributor2_id = int(match2.group(2))
        ratio1 = int(match2.group(3))
        ratio2 = int(match2.group(4))
        
        total = ratio1 + ratio2
        mixtures = [ratio1 / total, ratio2 / total]
        
        return {
            'N': 2,
            'contributor_ids': [contributor1_id, contributor2_id],
            'original_ratios': [ratio1, ratio2],
            'mixture_ratios': mixtures,
            'formatted_ratio': f"{ratio1}:{ratio2}"
        }
    
    # æ¨¡å¼2: ä¸‰äººæ··åˆæ ·æœ¬ - è´¡çŒ®è€…ID1_è´¡çŒ®è€…ID2_è´¡çŒ®è€…ID3-æ¯”ä¾‹1;æ¯”ä¾‹2;æ¯”ä¾‹3
    match3 = re.search(r'-(\d+)_(\d+)_(\d+)-(\d+);(\d+);(\d+)-', file_name)
    if match3:
        contributor_ids = [int(match3.group(i)) for i in range(1, 4)]
        ratios = [int(match3.group(i)) for i in range(4, 7)]
        
        total = sum(ratios)
        mixtures = [r / total for r in ratios]
        
        return {
            'N': 3,
            'contributor_ids': contributor_ids,
            'original_ratios': ratios,
            'mixture_ratios': mixtures,
            'formatted_ratio': ':'.join(map(str, ratios))
        }
    
    # æ¨¡å¼3: å››äººæ··åˆæ ·æœ¬
    match4 = re.search(r'-(\d+)_(\d+)_(\d+)_(\d+)-(\d+);(\d+);(\d+);(\d+)-', file_name)
    if match4:
        contributor_ids = [int(match4.group(i)) for i in range(1, 5)]
        ratios = [int(match4.group(i)) for i in range(5, 9)]
        
        total = sum(ratios)
        mixtures = [r / total for r in ratios]
        
        return {
            'N': 4,
            'contributor_ids': contributor_ids,
            'original_ratios': ratios,
            'mixture_ratios': mixtures,
            'formatted_ratio': ':'.join(map(str, ratios))
        }
    
    # æ¨¡å¼4: äº”äººæ··åˆæ ·æœ¬
    match5 = re.search(r'-(\d+)_(\d+)_(\d+)_(\d+)_(\d+)-(\d+);(\d+);(\d+);(\d+);(\d+)-', file_name)
    if match5:
        contributor_ids = [int(match5.group(i)) for i in range(1, 6)]
        ratios = [int(match5.group(i)) for i in range(6, 11)]
        
        total = sum(ratios)
        mixtures = [r / total for r in ratios]
        
        return {
            'N': 5,
            'contributor_ids': contributor_ids,
            'original_ratios': ratios,
            'mixture_ratios': mixtures,
            'formatted_ratio': ':'.join(map(str, ratios))
        }
    
    # æ¨¡å¼5: å•äººæ ·æœ¬
    match1 = re.search(r'-(\d+)-', file_name)
    if match1:
        contributor_id = int(match1.group(1))
        return {
            'N': 1,
            'contributor_ids': [contributor_id],
            'original_ratios': [1],
            'mixture_ratios': [1.0],
            'formatted_ratio': "1"
        }
    
    return None


class GenotypeEnumerator:
    """
    åŸºå› å‹æšä¸¾å™¨ - ç”Ÿæˆä¸è§‚æµ‹ç­‰ä½åŸºå› å…¼å®¹çš„æ‰€æœ‰å¯èƒ½åŸºå› å‹ç»„åˆ
    """
    
    def __init__(self, max_contributors: int = 5):
        self.max_contributors = max_contributors
        self.memo = {}  # ç¼“å­˜å·²è®¡ç®—çš„ç»“æœ
    
    def enumerate_valid_genotype_sets(self, observed_alleles: List[str], 
                                    N: int, K_top: int = None) -> List[List[Tuple[str, str]]]:
        """
        æšä¸¾æ‰€æœ‰ä¸è§‚æµ‹ç­‰ä½åŸºå› å…¼å®¹çš„åŸºå› å‹ç»„åˆ
        
        Args:
            observed_alleles: è§‚æµ‹åˆ°çš„ç­‰ä½åŸºå› åˆ—è¡¨
            N: è´¡çŒ®è€…æ•°é‡
            K_top: å¯¹äºN>=4æ—¶çš„K-topé‡‡æ ·æ•°é‡
            
        Returns:
            æ‰€æœ‰å¯èƒ½çš„åŸºå› å‹ç»„åˆåˆ—è¡¨
        """
        cache_key = (tuple(sorted(observed_alleles)), N, K_top)
        if cache_key in self.memo:
            return self.memo[cache_key]
        
        if N <= 3:
            # å¯¹äºN<=3ï¼Œæšä¸¾æ‰€æœ‰å¯èƒ½ç»„åˆ
            valid_sets = self._enumerate_all_combinations(observed_alleles, N)
        else:
            # å¯¹äºN>=4ï¼Œä½¿ç”¨K-topé‡‡æ ·ç­–ç•¥
            valid_sets = self._enumerate_k_top_combinations(observed_alleles, N, K_top)
        
        self.memo[cache_key] = valid_sets
        return valid_sets
    
    def _enumerate_all_combinations(self, observed_alleles: List[str], N: int) -> List[List[Tuple[str, str]]]:
        """æšä¸¾æ‰€æœ‰å¯èƒ½çš„åŸºå› å‹ç»„åˆï¼ˆé€‚ç”¨äºN<=3ï¼‰"""
        A_l = observed_alleles
        all_genotype_sets = []
        
        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„åŸºå› å‹
        possible_genotypes = []
        for i, a1 in enumerate(A_l):
            for j, a2 in enumerate(A_l):
                if i <= j:  # é¿å…é‡å¤ (a,b) å’Œ (b,a)
                    possible_genotypes.append((a1, a2))
        
        # ç”ŸæˆNä¸ªä¸ªä½“çš„æ‰€æœ‰åŸºå› å‹ç»„åˆ
        for genotype_combination in itertools.product(possible_genotypes, repeat=N):
            # æ£€æŸ¥è¿™ä¸ªç»„åˆæ˜¯å¦èƒ½è§£é‡Šæ‰€æœ‰è§‚æµ‹åˆ°çš„ç­‰ä½åŸºå› 
            if self._can_explain_alleles(list(genotype_combination), A_l):
                all_genotype_sets.append(list(genotype_combination))
        
        return all_genotype_sets
    
    def _enumerate_k_top_combinations(self, observed_alleles: List[str], 
                                    N: int, K_top: int) -> List[List[Tuple[str, str]]]:
        """ä½¿ç”¨K-topé‡‡æ ·ç­–ç•¥ï¼ˆé€‚ç”¨äºN>=4ï¼‰"""
        if K_top is None:
            K_top = min(1000, max(100, len(observed_alleles) ** N))
        
        A_l = observed_alleles
        possible_genotypes = []
        
        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„åŸºå› å‹
        for i, a1 in enumerate(A_l):
            for j, a2 in enumerate(A_l):
                if i <= j:
                    possible_genotypes.append((a1, a2))
        
        sampled_sets = []
        max_attempts = K_top * 10  # é˜²æ­¢æ— é™å¾ªç¯
        attempts = 0
        
        while len(sampled_sets) < K_top and attempts < max_attempts:
            attempts += 1
            
            # éšæœºé€‰æ‹©Nä¸ªåŸºå› å‹
            genotype_combination = [
                possible_genotypes[np.random.randint(len(possible_genotypes))]
                for _ in range(N)
            ]
            
            # æ£€æŸ¥æ˜¯å¦èƒ½è§£é‡Šè§‚æµ‹ç­‰ä½åŸºå› 
            if self._can_explain_alleles(genotype_combination, A_l):
                if genotype_combination not in sampled_sets:
                    sampled_sets.append(genotype_combination)
        
        return sampled_sets
    
    def _can_explain_alleles(self, genotype_set: List[Tuple[str, str]], 
                           observed_alleles: List[str]) -> bool:
        """
        æ£€æŸ¥åŸºå› å‹ç»„åˆæ˜¯å¦èƒ½è§£é‡Šæ‰€æœ‰è§‚æµ‹åˆ°çš„ç­‰ä½åŸºå› 
        ï¼ˆå…è®¸ADOï¼Œå³åŸºå› å‹ä¸­çš„ç­‰ä½åŸºå› å¯ä»¥ä¸åœ¨è§‚æµ‹ä¸­å‡ºç°ï¼‰
        """
        # ä»åŸºå› å‹ç»„åˆä¸­æ”¶é›†æ‰€æœ‰ç­‰ä½åŸºå› 
        genotype_alleles = set()
        for genotype in genotype_set:
            if genotype is not None:
                genotype_alleles.update(genotype)
        
        # æ£€æŸ¥æ‰€æœ‰è§‚æµ‹ç­‰ä½åŸºå› æ˜¯å¦éƒ½èƒ½è¢«åŸºå› å‹ç»„åˆè§£é‡Š
        observed_set = set(observed_alleles)
        return observed_set.issubset(genotype_alleles)


class PseudoFrequencyCalculator:
    """
    ä¼ªç­‰ä½åŸºå› é¢‘ç‡è®¡ç®—å™¨ - åŸºäºé™„ä»¶2æ•°æ®æ¨ç®—ä½ç‚¹ç‰¹å¼‚æ€§é¢‘ç‡
    """
    
    def __init__(self):
        self.frequency_cache = {}
    
    def calculate_pseudo_frequencies(self, locus: str, 
                                   all_observed_alleles_in_att2: List[str]) -> Dict[str, float]:
        """
        è®¡ç®—ä½ç‚¹çš„ä¼ªç­‰ä½åŸºå› é¢‘ç‡
        
        Args:
            locus: ä½ç‚¹åç§°
            all_observed_alleles_in_att2: é™„ä»¶2ä¸­è¯¥ä½ç‚¹è§‚æµ‹åˆ°çš„æ‰€æœ‰ç­‰ä½åŸºå› 
            
        Returns:
            ç­‰ä½åŸºå› é¢‘ç‡å­—å…¸
        """
        cache_key = (locus, tuple(sorted(all_observed_alleles_in_att2)))
        if cache_key in self.frequency_cache:
            return self.frequency_cache[cache_key]
        
        # ç»Ÿè®¡ç­‰ä½åŸºå› å‡ºç°æ¬¡æ•°
        allele_counts = {}
        for allele in all_observed_alleles_in_att2:
            allele_counts[allele] = allele_counts.get(allele, 0) + 1
        
        # è®¡ç®—é¢‘ç‡
        total_count = sum(allele_counts.values())
        frequencies = {}
        
        for allele, count in allele_counts.items():
            frequencies[allele] = count / total_count
        
        # ä¸ºæœªè§‚æµ‹åˆ°ä½†å¯èƒ½å­˜åœ¨çš„ç­‰ä½åŸºå› åˆ†é…æœ€å°é¢‘ç‡
        min_freq = 1 / (2 * len(all_observed_alleles_in_att2) + len(allele_counts))
        
        # æ ‡å‡†åŒ–é¢‘ç‡ï¼Œç¡®ä¿æ€»å’Œä¸º1
        freq_sum = sum(frequencies.values())
        for allele in frequencies:
            frequencies[allele] = frequencies[allele] / freq_sum * (1 - min_freq * 2)
        
        self.frequency_cache[cache_key] = frequencies
        return frequencies
    
    def calculate_genotype_prior(self, genotype: Tuple[str, str], 
                               frequencies: Dict[str, float]) -> float:
        """
        åŸºäºHWEè®¡ç®—åŸºå› å‹çš„å…ˆéªŒæ¦‚ç‡
        
        Args:
            genotype: åŸºå› å‹ (allele1, allele2)
            frequencies: ç­‰ä½åŸºå› é¢‘ç‡
            
        Returns:
            åŸºå› å‹å…ˆéªŒæ¦‚ç‡
        """
        a1, a2 = genotype
        f1 = frequencies.get(a1, 1e-6)
        f2 = frequencies.get(a2, 1e-6)
        
        if a1 == a2:  # çº¯åˆå­
            return f1 * f2
        else:  # æ‚åˆå­
            return 2 * f1 * f2
    
    def calculate_genotype_set_prior(self, genotype_set: List[Tuple[str, str]], 
                                   frequencies: Dict[str, float]) -> float:
        """
        è®¡ç®—æ•´ä¸ªåŸºå› å‹ç»„åˆçš„å…ˆéªŒæ¦‚ç‡
        
        Args:
            genotype_set: åŸºå› å‹ç»„åˆ
            frequencies: ç­‰ä½åŸºå› é¢‘ç‡
            
        Returns:
            ç»„åˆå…ˆéªŒæ¦‚ç‡
        """
        log_prior = 0.0
        for genotype in genotype_set:
            if genotype is not None:
                prior = self.calculate_genotype_prior(genotype, frequencies)
                log_prior += np.log(max(prior, 1e-10))
        
        return log_prior


class MCMCMixtureInference_Corrected:
    """
    ä¿®æ­£ç‰ˆMCMCæ··åˆæ¯”ä¾‹æ¨æ–­ç±» - å®ç°æ­£ç¡®çš„åŸºå› å‹è¾¹ç¼˜åŒ–å’Œæ··åˆæ¯”ä¾‹è§£æ
    """
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–MCMCæ¨æ–­å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.marker_params = self.config.get("marker_specific_params", {})
        self.global_params = self.config.get("global_parameters", {})
        
        # åˆå§‹åŒ–å‚æ•°
        self._init_parameters()
        
        # åˆå§‹åŒ–è¾…åŠ©ç±»
        self.genotype_enumerator = GenotypeEnumerator()
        self.pseudo_freq_calculator = PseudoFrequencyCalculator()
        
        # MCMCç»“æœå­˜å‚¨
        self.mcmc_results = {}
        self.convergence_diagnostics = {}
        
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {
                "global_parameters": {
                    "saturation_threshold_rfu": 30000.0,
                    "size_tolerance_bp": 0.5,
                    "stutter_cv_hs_global_n_minus_1": 0.25,
                    "true_allele_confidence_threshold": 0.5
                },
                "marker_specific_params": {}
            }
    
    def _init_parameters(self):
        """åˆå§‹åŒ–æ¨¡å‹å‚æ•°"""
        # åŸºç¡€å‚æ•° - æ¥è‡ªV5ç‰¹å¾çš„åŠ¨æ€è®¡ç®—
        self.k_gamma = self.global_params.get("k_gamma", 1.0)
        self.beta = self.global_params.get("beta", 1.5)
        
        # æ–¹å·®å‚æ•°
        self.sigma_var_base = self.global_params.get("sigma_var_base", 0.1)
        self.c1 = self.global_params.get("c1", 0.5)
        self.c2 = self.global_params.get("c2", 0.3)
        self.c3 = self.global_params.get("c3", 0.2)
        
        # Stutter CVå‚æ•°
        self.cv_hs_base = self.global_params.get("cv_hs_base", 0.25)
        self.A_s = self.global_params.get("A_s", 0.1)
        self.B_s = self.global_params.get("B_s", 0.001)
        
        # ADOå‚æ•°
        self.H_50 = self.global_params.get("ado_h50", 200.0)
        self.s_ado = self.global_params.get("ado_slope", 0.01)
        
        # é™è§£å‚æ•°
        self.k_deg_0 = self.global_params.get("k_deg_0", 0.001)
        self.size_ref = self.global_params.get("size_ref", 100.0)
        self.alpha = self.global_params.get("alpha", 1.0)
        
        # MCMCå‚æ•°
        self.n_chains = self.global_params.get("n_chains", 4)
        self.n_iterations = self.global_params.get("n_iterations", 50000)
        self.n_warmup = self.global_params.get("n_warmup", 12500)
        self.thinning = self.global_params.get("thinning", 5)
        
        # K-topå‚æ•°
        self.K_top = self.global_params.get("K_top", 500)
    
    def load_real_data_with_correct_parsing(self) -> Tuple[int, Dict, Dict, Dict]:
        """
        åŠ è½½çœŸå®æ•°æ®æ–‡ä»¶ï¼Œæ­£ç¡®è§£ææ··åˆæ¯”ä¾‹
        
        Returns:
            N: è´¡çŒ®è€…äººæ•°
            mx_phi: æ··åˆæ¯”ä¾‹å’Œphiå‚æ•°
            E_obs: è§‚æµ‹æ•°æ®  
            pseudo_freq: ä¼ªé¢‘ç‡
        """
        print("åŠ è½½çœŸå®æ•°æ®å¹¶æ­£ç¡®è§£ææ··åˆæ¯”ä¾‹...")
        
        # 1. åŠ è½½é™„ä»¶1æ•°æ®å¹¶è§£ææ··åˆæ¯”ä¾‹
        try:
            str_data = pd.read_csv('é™„ä»¶1ï¼šä¸åŒäººæ•°çš„STRå›¾è°±æ•°æ®.csv')
            print(f"âœ“ æˆåŠŸåŠ è½½é™„ä»¶1æ•°æ®: {str_data.shape}")
            
            # è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ä¿¡æ¯
            first_sample = str_data['Sample File'].iloc[0]
            parsed_info = parse_sample_file_name(first_sample)
            
            if parsed_info:
                N = parsed_info['N']
                true_mixture_ratios = np.array(parsed_info['mixture_ratios'])
                contributor_ids = parsed_info['contributor_ids']
                
                print(f"âœ“ è§£ææ ·æœ¬: {first_sample}")
                print(f"  - è´¡çŒ®è€…æ•°é‡: {N}")
                print(f"  - è´¡çŒ®è€…ID: {contributor_ids}")
                print(f"  - åŸå§‹æ¯”ä¾‹: {parsed_info['formatted_ratio']}")
                print(f"  - æ··åˆæ¯”ä¾‹: {[f'{r:.3f}' for r in true_mixture_ratios]}")
            else:
                print("âš ï¸ æ— æ³•è§£ææ ·æœ¬æ–‡ä»¶åï¼Œä½¿ç”¨é»˜è®¤å€¼")
                N = 2
                true_mixture_ratios = np.array([0.6, 0.4])
                contributor_ids = [40, 41]
        except Exception as e:
            print(f"âœ— åŠ è½½é™„ä»¶1æ•°æ®å¤±è´¥: {e}")
            N = 2
            true_mixture_ratios = np.array([0.6, 0.4])
            contributor_ids = [40, 41]
        
        # 2. åŠ è½½é™„ä»¶3çš„åŸºå› å‹æ•°æ®
        try:
            genotype_data = pd.read_csv('é™„ä»¶3ï¼šå„ä¸ªè´¡çŒ®è€…å¯¹åº”çš„åŸºå› å‹æ•°æ®.csv')
            print(f"âœ“ æˆåŠŸåŠ è½½é™„ä»¶3æ•°æ®: {genotype_data.shape}")
            
            # æå–å¯¹åº”è´¡çŒ®è€…çš„åŸºå› å‹
            contributor_genotypes = {}
            for contrib_id in contributor_ids:
                contrib_row = genotype_data[genotype_data['Sample ID'] == contrib_id]
                if not contrib_row.empty:
                    contributor_genotypes[contrib_id] = contrib_row.iloc[0].to_dict()
                    print(f"  - è´¡çŒ®è€…{contrib_id}çš„åŸºå› å‹æ•°æ®å·²æå–")
        except Exception as e:
            print(f"âœ— åŠ è½½é™„ä»¶3æ•°æ®å¤±è´¥: {e}")
            contributor_genotypes = {}
        
        # 3. æ„å»ºè§‚æµ‹æ•°æ®E_obs
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ ¹æ®STRå›¾è°±æ•°æ®æ„å»º
        E_obs = self._create_observed_data_from_genotypes(
            contributor_genotypes, true_mixture_ratios, N)
        
        # 4. æ„å»ºphiå‚æ•°
        phi_star = {
            'gamma_l': 1000,  # é»˜è®¤æ”¾å¤§æ•ˆç‡
            'sigma_var_l': 0.15,  # æ ¹æ®æ··åˆæ¯”ä¾‹è°ƒæ•´æ–¹å·®
            'k_deg': 0.0001,
            'size_ref': 200,
            'h50': 150,
            's_ado': 1.5
        }
        
        mx_phi = {
            'mx_star': true_mixture_ratios,
            'phi_star': phi_star,
            'N': N,
            'contributor_ids': contributor_ids,
            'parsed_info': parsed_info
        }
        
        # 5. æ„å»ºä¼ªé¢‘ç‡
        pseudo_freq = self._create_pseudo_frequencies_from_att3(genotype_data)
        
        print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ")
        print(f"  - è§‚æµ‹ä½ç‚¹æ•°: {len(E_obs)}")
        print(f"  - ä¼ªé¢‘ç‡ä½ç‚¹æ•°: {len(pseudo_freq)}")
        
        return N, mx_phi, E_obs, pseudo_freq
    
    def _create_observed_data_from_genotypes(self, contributor_genotypes: Dict, 
                                           mixture_ratios: np.ndarray, N: int) -> Dict:
        """
        åŸºäºè´¡çŒ®è€…åŸºå› å‹å’Œæ··åˆæ¯”ä¾‹åˆ›å»ºè§‚æµ‹æ•°æ®
        
        Args:
            contributor_genotypes: è´¡çŒ®è€…åŸºå› å‹æ•°æ®
            mixture_ratios: æ··åˆæ¯”ä¾‹
            N: è´¡çŒ®è€…æ•°é‡
            
        Returns:
            è§‚æµ‹æ•°æ®å­—å…¸
        """
        # STRä½ç‚¹åˆ—è¡¨
        str_loci = ['D8S1179', 'D21S11', 'D7S820', 'CSF1PO', 'D3S1358', 
                   'TH01', 'D13S317', 'D16S539', 'D2S1338', 'D19S433', 
                   'vWA', 'TPOX', 'D18S51', 'D5S818', 'FGA']
        
        E_obs = {}
        
        for locus in str_loci:
            # æ”¶é›†è¯¥ä½ç‚¹çš„æ‰€æœ‰ç­‰ä½åŸºå› 
            locus_alleles = set()
            locus_heights = {}
            
            for i, (contrib_id, genotype_data) in enumerate(contributor_genotypes.items()):
                if i >= N:  # åªå¤„ç†å‰Nä¸ªè´¡çŒ®è€…
                    break
                    
                if locus in genotype_data:
                    allele_str = str(genotype_data[locus])
                    if pd.notna(allele_str) and allele_str != 'nan':
                        # è§£æåŸºå› å‹ (ä¾‹å¦‚: "15,16" æˆ– "15")
                        alleles = [a.strip() for a in allele_str.split(',')]
                        
                        for allele in alleles:
                            if allele and allele != '':
                                locus_alleles.add(allele)
                                
                                # æ¨¡æ‹Ÿå³°é«˜ (åŸºäºæ··åˆæ¯”ä¾‹)
                                base_height = 1000 * mixture_ratios[i]
                                noise = np.random.lognormal(0, 0.1)
                                height = max(50, base_height * noise)
                                
                                if allele in locus_heights:
                                    locus_heights[allele] += height
                                else:
                                    locus_heights[allele] = height
            
            if locus_alleles:
                E_obs[locus] = {
                    'locus': locus,
                    'alleles': list(locus_alleles),
                    'heights': locus_heights
                }
        
        return E_obs
    
    def _create_pseudo_frequencies_from_att3(self, genotype_data: pd.DataFrame) -> Dict:
        """
        åŸºäºé™„ä»¶3åˆ›å»ºä¼ªç­‰ä½åŸºå› é¢‘ç‡
        
        Args:
            genotype_data: é™„ä»¶3çš„åŸºå› å‹æ•°æ®
            
        Returns:
            ä¼ªé¢‘ç‡å­—å…¸
        """
        str_loci = ['D8S1179', 'D21S11', 'D7S820', 'CSF1PO', 'D3S1358',
                   'TH01', 'D13S317', 'D16S539', 'D2S1338', 'D19S433',
                   'vWA', 'TPOX', 'D18S51', 'D5S818', 'FGA']
        
        pseudo_freq = {}
        
        for locus in str_loci:
            if locus in genotype_data.columns:
                # æ”¶é›†è¯¥ä½ç‚¹çš„æ‰€æœ‰ç­‰ä½åŸºå› 
                all_alleles = []
                
                for _, row in genotype_data.iterrows():
                    allele_str = str(row[locus])
                    if pd.notna(allele_str) and allele_str != 'nan':
                        alleles = [a.strip() for a in allele_str.split(',')]
                        all_alleles.extend([a for a in alleles if a])
                
                # è®¡ç®—é¢‘ç‡
                if all_alleles:
                    freq = self.pseudo_freq_calculator.calculate_pseudo_frequencies(
                        locus, all_alleles)
                    pseudo_freq[locus] = freq
        
        return pseudo_freq
    
    # ç»§ç»­åŒ…å«åŸæœ‰çš„å…¶ä»–æ–¹æ³•...
    def calculate_gamma_l(self, locus: str, v5_features: Dict) -> float:
        """åŸºäºV5ç‰¹å¾è®¡ç®—ä½ç‚¹ç‰¹å¼‚æ€§æ”¾å¤§æ•ˆç‡ Î³_l"""
        avg_height = v5_features.get('avg_peak_height', 1000.0)
        gamma_base = self.k_gamma * avg_height
        inter_locus_entropy = v5_features.get('inter_locus_balance_entropy', 1.0)
        
        L_exp = len(self.marker_params) if self.marker_params else 10
        if L_exp > 1:
            w_entropy = (1 - inter_locus_entropy / np.log(L_exp)) ** self.beta
            P_l = 1.0 / L_exp
            gamma_l = gamma_base * (1 + w_entropy * ((P_l * L_exp) - 1))
        else:
            gamma_l = gamma_base
            
        return max(gamma_l, 1e-3)
    
    def calculate_sigma_var_l(self, locus: str, v5_features: Dict) -> float:
        """åŸºäºV5ç‰¹å¾è®¡ç®—ä½ç‚¹æ–¹å·®å‚æ•° Ïƒ_var,l"""
        avg_height = v5_features.get('avg_peak_height', 1000.0)
        R_PHR = v5_features.get('ratio_severe_imbalance_loci', 0.0)
        gamma_1 = v5_features.get('skewness_peak_height', 0.0)
        H_a_bar = max(v5_features.get('avg_locus_allele_entropy', 1.0), 1e-6)
        
        A_f = self.global_params.get("A_f", 1.0)
        B_f = self.global_params.get("B_f", 0.001)
        h_0f = self.global_params.get("h_0f", 1000.0)
        
        f_h = 1 + A_f / (1 + np.exp(B_f * (avg_height - h_0f)))
        
        sigma_var = (self.sigma_var_base * 
                    (1 + self.c1 * R_PHR + self.c2 * abs(gamma_1) + self.c3 * (1 / H_a_bar)) * 
                    f_h)
        
        return max(sigma_var, 0.01)


def main():
    """
    ä¸»å‡½æ•° - æ¼”ç¤ºä¿®æ­£ç‰ˆé—®é¢˜2çš„MCMCæ··åˆæ¯”ä¾‹æ¨æ–­
    """
    print("=" * 80)
    print("é—®é¢˜2ï¼šMCMCæ··åˆæ¯”ä¾‹æ¨æ–­ (ä¿®æ­£ç‰ˆ V10.2 - æ­£ç¡®è§£ææ··åˆæ¯”ä¾‹)")
    print("=" * 80)
    
    # 1. åˆå§‹åŒ–ä¿®æ­£ç‰ˆMCMCæ¨æ–­å™¨
    config_path = './config_params.json'
    mcmc_inferencer = MCMCMixtureInference_Corrected(config_path)
    
    # 2. åŠ è½½çœŸå®æ•°æ®å¹¶æ­£ç¡®è§£ææ··åˆæ¯”ä¾‹
    print("\n=== åŠ è½½çœŸå®æ•°æ®å¹¶è§£ææ··åˆæ¯”ä¾‹ ===")
    try:
        N, mx_phi, E_obs, pseudo_freq = mcmc_inferencer.load_real_data_with_correct_parsing()
        print("âœ… æˆåŠŸåŠ è½½å¹¶è§£æçœŸå®æ•°æ®")
        
        # æ˜¾ç¤ºè§£æç»“æœ
        parsed_info = mx_phi.get('parsed_info', {})
        if parsed_info:
            print(f"\nğŸ“Š æ··åˆæ¯”ä¾‹è§£æç»“æœ:")
            print(f"   è´¡çŒ®è€…æ•°é‡: {parsed_info['N']}")
            print(f"   è´¡çŒ®è€…ID: {parsed_info['contributor_ids']}")
            print(f"   åŸå§‹æ¯”ä¾‹: {parsed_info['formatted_ratio']}")
            print(f"   æ ‡å‡†åŒ–æ··åˆæ¯”ä¾‹: {[f'{r:.4f}' for r in parsed_info['mixture_ratios']]}")
            print(f"   æ··åˆæ¯”ä¾‹æ€»å’Œ: {sum(parsed_info['mixture_ratios']):.6f}")
    except Exception as e:
        print(f"âš ï¸ åŠ è½½çœŸå®æ•°æ®å¤±è´¥: {e}")
        print("ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®")
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        N = 2
        mx_phi = {
            'mx_star': np.array([0.2, 0.8]),  # å¯¹åº”1:4çš„æ¯”ä¾‹
            'phi_star': {'gamma_l': 1000, 'sigma_var_l': 0.15},
            'N': N
        }
        E_obs = {}
        pseudo_freq = {}
    
    # 3. æ˜¾ç¤ºæ•°æ®æ‘˜è¦
    print(f"\n=== æ•°æ®æ‘˜è¦ ===")
    print(f"è´¡çŒ®è€…æ•°é‡: {N}")
    print(f"è§‚æµ‹ä½ç‚¹æ•°: {len(E_obs)}")
    print(f"çœŸå®æ··åˆæ¯”ä¾‹: {mx_phi['mx_star']}")
    
    # æ˜¾ç¤ºå„ä½ç‚¹çš„è§‚æµ‹ç­‰ä½åŸºå› 
    print(f"\nğŸ“ å„ä½ç‚¹è§‚æµ‹ç­‰ä½åŸºå› :")
    for locus, data in list(E_obs.items())[:5]:  # æ˜¾ç¤ºå‰5ä¸ªä½ç‚¹
        alleles = data['alleles']
        heights = data['heights']
        print(f"   {locus}: {alleles} (å³°é«˜èŒƒå›´: {min(heights.values()):.0f}-{max(heights.values()):.0f})")
    
    if len(E_obs) > 5:
        print(f"   ... è¿˜æœ‰ {len(E_obs)-5} ä¸ªä½ç‚¹")
    
    print(f"\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼Œå¯ä»¥è¿›è¡ŒMCMCæ¨æ–­")
    print("=" * 80)
    
    return N, mx_phi, E_obs, pseudo_freq


if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡ç°
    np.random.seed(42)
    
    try:
        N, mx_phi, E_obs, pseudo_freq = main()
        
        print("\nğŸ‰ æ··åˆæ¯”ä¾‹è§£æå’Œæ•°æ®åŠ è½½å®Œæˆ!")
        print("ç°åœ¨å¯ä»¥ç»§ç»­è¿›è¡ŒMCMCé‡‡æ ·å’Œæ¨æ–­...")
        
        # éªŒè¯æ··åˆæ¯”ä¾‹è§£æ
        true_ratios = mx_phi['mx_star']
        print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
        print(f"   è§£æçš„æ··åˆæ¯”ä¾‹: {true_ratios}")
        print(f"   æ¯”ä¾‹æ€»å’Œ: {sum(true_ratios):.6f}")
        print(f"   æ˜¯å¦æ ‡å‡†åŒ–: {'âœ…' if abs(sum(true_ratios) - 1.0) < 1e-6 else 'âŒ'}")
        
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­äº†ç¨‹åºæ‰§è¡Œ")
    except Exception as e:
        print(f"\nç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()